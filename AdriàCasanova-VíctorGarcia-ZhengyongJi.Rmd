---
title: "SIM. Assignment 1: House Prices"
author: "Adrià Casanova, Víctor Garcia, Zhengyong Ji"
date: "2023-11-19"
output: pdf_document
---
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    toc: yes
    toc_depth: 3
    number_sections: no
editor_options:
  chunk_output_type: console
---
In this work, we will study the data set called “Ames Housing dataset”, collected by Dean De Cock for the purpose to analyze the correlation about house prices and different features that describe the house condition, and then to build a regression model that will allow us to predict the sale price.

All members have contributed equally to all parts of the project.

The data set has two parts, the training part and testing part, with 1460 and 1459 observations each other, and 81 variables (including the id variable).

```{r, echo=T, message=FALSE, warning=FALSE, results='hide'}
# Delete any existing object
if(!is.null(dev.list())) dev.off()
rm(list = ls())

library(car)
library(mice)
library(dplyr) 
library(missMDA)
library(FactoMineR)
library(chemometrics)
library(DataExplorer)
library(corrplot)
library(DataExplorer)
library(MASS)
library(effects)

train = read.csv("train.csv")
test = read.csv("test.csv")

#Create EDA report before any data preparation
#create_report(train, output_format = "pdf_document", output_file = "train.pdf")
#create_report(test, output_format = "pdf_document", output_file = "test.pdf")
```

# 0. Data preparation and data cleaning
After loading the datasets we defined the types of the variables (categorical, numerical or dates). Some of them required further transformation, based on some assumptions, that are detailed below. 

```{r,  warning=FALSE, results='hide'}
Categorical_val = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC","CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature","SaleType","SaleCondition", "MoSold")

Numerical_val = c("LotFrontage","LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal","YearBuilt","YearRemodAdd","GarageYrBlt","YrSold")

Date_val = c("YearBuilt","YearRemodAdd","GarageYrBlt","MoSold","YrSold")

# Identify variables susceptible to be transformed into categorical
sapply(dplyr::select(train, Numerical_val), table)
sapply(dplyr::select(train, Categorical_val), table)
sapply(dplyr::select(train, Date_val), table)
```

1) Non applicable NaN's: There were 3 variables with an important number of missing (aprox 90%) because the measure was not applicable. This happened, firstly, in PoolArea because the pool area can not be computed for houses without a pool. It was also the case of LowQualFinSF because it is only refered to surfaces finished with low quality, and with BsmtFinSF2, that is only applicable for basement of type 2.
Our solution was to define those three variables as binary variables.

```{r}
# As we can see there are an important number of Nan
# PoolArea: 99% missings
length(which(train$PoolArea > 0))/dim(train)[1]*100
length(which(test$PoolArea > 0))/dim(test)[1]*100

# LowQualFinSF: 98% missings
length(which(train$LowQualFinSF > 0))/dim(train)[1]*100
length(which(test$LowQualFinSF > 0))/dim(test)[1]*100

#BsmtFinSF2: 89% missings
length(which(train$BsmtFinSF2 > 0))/dim(train)[1]*100
length(which(test$BsmtFinSF2 > 0))/dim(test)[1]*100

# Under the assumption 1, we transform the variables to binary
test <- test %>%
  mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
test$PoolArea = as.factor(test$PoolArea)
train <- train %>%
  mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
train$PoolArea = as.factor(train$PoolArea)

test <- test %>%
  mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
test$LowQualFinSF = as.factor(test$LowQualFinSF)
train <- train %>%
  mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
train$LowQualFinSF = as.factor(train$LowQualFinSF)

test <- test %>%
  mutate(BsmtFinSF2 = ifelse(BsmtFinSF2 > 0, "Yes", "No"))
test$BsmtFinSF2 = as.factor(test$BsmtFinSF2)
train <- train %>%
  mutate(BsmtFinSF2 = ifelse(BsmtFinSF2 > 0, "Yes", "No"))
train$BsmtFinSF2 = as.factor(train$BsmtFinSF2)
```

2) LotFrontage, which represents the distance from the property to the street, has a high percentage of missing values, 18% in "train" and 16% in "test". A quick look at the summary in both datasets shows there is not any house with a value of 0 for this variable. However, in the real world there exist houses whose entrance is right next to the street, with no separation from it. Hence, we deduce that missing values correspond to a distance of 0 and we impute LotFrontage like so.

```{r}
#Analysis of the percentage of missings
percent_miss <- function(data) {
  return (length(which(is.na(data)))/length(data)*100)
}
percent_miss(train$LotFrontage)
percent_miss(test$LotFrontage)

# Transformation Na'n to 0
lltrain <- which(is.na(train$LotFrontage))
lltest <- which(is.na(test$LotFrontage))
train$LotFrontage[lltrain] <- 0
test$LotFrontage[lltest] <- 0
```

3) Only few values possible: Variables BsmtHalfBath KitchenAbvGr have only 3 and 4 values possible, so we transform them into categorical

```{r}
# BsmtHalfBath is numerical but it can only be 0, 1 or 2
length(which(train$BsmtHalfBath > 0))/dim(train)[1]*100
length(which(test$BsmtHalfBath > 0))/dim(test)[1]*100

#KitchenAbvGr can only be 0, 1, 2 or 3
length(which(train$KitchenAbvGr != 1))/dim(train)[1]*100
length(which(test$KitchenAbvGr != 1))/dim(test)[1]*100

#Transformation into categorical
train$BsmtHalfBath <- as.factor(train$BsmtHalfBath)
test$BsmtHalfBath <- as.factor(test$BsmtHalfBath)

train$KitchenAbvGr <- as.factor(train$KitchenAbvGr)
test$KitchenAbvGr <- as.factor(test$KitchenAbvGr)
levels(test$KitchenAbvGr) = c(levels(test$KitchenAbvGr),"3")
```

4) Variables with too many categories: OverallQual, Neighborhood and MSSubClass have too many levels to study their interactions in the models we will create later. Hence, we aggregate their categories following logical criterias. Even though, these will create a bias in the model, it will allow us to study their effect on the target. That being said, OverallQual will have 5 ordered levels.

```{r}
t.train <- table(train$OverallQual); t.train
t.test <- table(test$OverallQual); t.test

par(mfrow=c(1,2))
barplot(t.train, main = "train$OverallQual")
barplot(t.test, main = "test$OverallQual")
par(mfrow=c(1,1))

train$OverallQual <- replace(train$OverallQual, train$OverallQual %in% 1:2, "VBad")
train$OverallQual <- replace(train$OverallQual, train$OverallQual %in% 3:4, "Bad")
train$OverallQual <- replace(train$OverallQual, train$OverallQual %in% 5:6, "Moderate")
train$OverallQual <- replace(train$OverallQual, train$OverallQual %in% 7:8, "Good")
train$OverallQual <- replace(train$OverallQual, train$OverallQual %in% 9:10, "VGood")

test$OverallQual <- replace(test$OverallQual, test$OverallQual %in% 1:2, "VBad")
test$OverallQual <- replace(test$OverallQual, test$OverallQual %in% 3:4, "Bad")
test$OverallQual <- replace(test$OverallQual, test$OverallQual %in% 5:6, "Moderate")
test$OverallQual <- replace(test$OverallQual, test$OverallQual %in% 7:8, "Good")
test$OverallQual <- replace(test$OverallQual, test$OverallQual %in% 9:10, "VGood")

train$OverallQual <- factor(train$OverallQual, levels = c("VBad", "Bad", "Moderate", "Good", "VGood"))
test$OverallQual <- factor(test$OverallQual, levels = c("VBad", "Bad","Moderate", "Good","VGood"))

t.train2 <- table(train$OverallQual); t.train2
t.test2 <- table(test$OverallQual); t.test2

barplot(t.train2, main = "train$OverallQual")
barplot(t.test2, main = "test$OverallQual")
```

Neighborhood will have 3 ordered levels ("Poor", "Moderate" or "Rich") following the real-estate order found in https://www.neighborhoodscout.com/ia/ames/real-estate. 

```{r}
t.train <- table(train$Neighborhood); t.train
t.test <- table(test$Neighborhood); t.test

Rich = c("NoRidge", "NridgHt", "StoneBr", "Timber", "Veenker", "Somerst", "ClearCr", "Crawfor")
Moderate = c("SWISU", "CollgCr", "Blueste", "Blmngtn", "Gilbert", "Mitchel", "NWAmes", "NPkVill")
Poor = c("Edwards", "BrDale", "BrkSide", "IDOTRR", "MeadowV", "NAmes", "OldTown", "Sawyer", "SawyerW")

train$Neighborhood <- replace(train$Neighborhood, train$Neighborhood %in% Poor, "Poor")
train$Neighborhood <- replace(train$Neighborhood, train$Neighborhood %in% Moderate, "Moderate")
train$Neighborhood <- replace(train$Neighborhood, train$Neighborhood %in% Rich, "Rich")

test$Neighborhood <- replace(test$Neighborhood, test$Neighborhood %in% Poor, "Poor")
test$Neighborhood <- replace(test$Neighborhood, test$Neighborhood %in% Moderate, "Moderate")
test$Neighborhood <- replace(test$Neighborhood, test$Neighborhood %in% Rich, "Rich")

train$Neighborhood <- factor(train$Neighborhood, levels = c("Poor", "Moderate", "Rich"))
test$Neighborhood <- factor(test$Neighborhood, levels = c("Poor", "Moderate", "Rich"))

t.train2 <- table(train$Neighborhood); t.train2
t.test2 <- table(test$Neighborhood); t.test2

barplot(t.train2, main = "Train Neighborhood")
barplot(t.test2, main = "Test Neighborhood")
```

4) Non applicable 0's: There are three variables that represent the area of different types of porches (EnclosedPorch, X3SsnPorch and ScreenPorch). In all of them, there is an important percentatge of 0's (about 90%). As a consequence, we consider that it is more efficient to treat those variables as binary to have a more balanced variable and because the univariate analysis of those variables, like outlier detection, of those variables would be very complicated, as their IQR was 0.

```{r}
# Calculation of the % of non 0's
length(which(train$EnclosedPorch > 0))/dim(train)[1]*100
length(which(test$EnclosedPorch > 0))/dim(test)[1]*100

length(which(train$X3SsnPorch > 0))/dim(train)[1]*100
length(which(test$X3SsnPorch > 0))/dim(test)[1]*100

length(which(train$ScreenPorch > 0))/dim(train)[1]*100
length(which(test$ScreenPorch > 0))/dim(test)[1]*100

#Transformation of the variables into binary
test <- test %>%
  mutate(EnclosedPorch = ifelse(EnclosedPorch > 0, "Yes", "No"))
test$EnclosedPorch = as.factor(test$EnclosedPorch)
train <- train %>%
  mutate(EnclosedPorch = ifelse(EnclosedPorch > 0, "Yes", "No"))
train$EnclosedPorch = as.factor(train$EnclosedPorch)

test <- test %>%
  mutate(X3SsnPorch = ifelse(X3SsnPorch > 0, "Yes", "No"))
test$X3SsnPorch = as.factor(test$X3SsnPorch)
train <- train %>%
  mutate(X3SsnPorch = ifelse(X3SsnPorch > 0, "Yes", "No"))
train$X3SsnPorch = as.factor(train$X3SsnPorch)

test <- test %>%
  mutate(ScreenPorch = ifelse(ScreenPorch > 0, "Yes", "No"))
test$ScreenPorch = as.factor(test$ScreenPorch)
train <- train %>%
  mutate(ScreenPorch = ifelse(ScreenPorch > 0, "Yes", "No"))
train$ScreenPorch = as.factor(train$ScreenPorch)
```

5) Redundant variable: MiscVal, that measures the price of a miscellaneous feature (like having an elevator) has a lot of 0's (96%) as it is only applicable for some properties. Moreover, the information of the properties that have a miscellaneous feature can be also optained in "MiscFeature" variable. Consequently, we decided to remove this variable from the analysis.

```{r}
# Analysis of non 0's
length(which(train$MiscVal > 0))/dim(train)[1]*100
length(which(test$MiscVal > 0))/dim(test)[1]*100

miscVal_train <- train$MiscVal
miscVal_test <- test$MiscVal
train$MiscVal <- NULL
test$MiscVal <- NULL
```

6) Creation of a new level for categorical: Because we do not know if all the Nan's in categorical variables are at random we decided that we will not impute any categorical. Consequently, we created a new level for all the missings.

```{r}
# Declaration of a categorical as factor variables with a new level, "Nan"
levels(train$Alley) <- c(levels(train$Alley), "NAlley")
train$Alley[which(is.na(train$Alley))] <- "NAlley"
levels(test$Alley) <- c(levels(test$Alley), "NAlley")
test$Alley[which(is.na(test$Alley))] <- "NAlley"

levels(train$BsmtQual) <- c(levels(train$BsmtQual), "NBsmt")
train$BsmtQual[which(is.na(train$BsmtQual))] <- "NBsmt"
levels(test$BsmtQual) <- c(levels(test$BsmtQual), "NBsmt")
test$BsmtQual[which(is.na(test$BsmtQual))] <- "NBsmt"

levels(train$BsmtCond) <- c(levels(train$BsmtCond), "NBsmt")
train$BsmtCond[which(is.na(train$BsmtCond))] <- "NBsmt"
levels(test$BsmtCond) <- c(levels(test$BsmtCond), "NBsmt")
test$BsmtCond[which(is.na(test$BsmtCond))] <- "NBsmt"

levels(train$BsmtExposure) <- c(levels(train$BsmtExposure), "NBsmt")
train$BsmtExposure[which(is.na(train$BsmtExposure))] <- "NBsmt"
levels(test$BsmtExposure) <- c(levels(test$BsmtExposure), "NBsmt")
test$BsmtExposure[which(is.na(test$BsmtExposure))] <- "NBsmt"

levels(train$BsmtFinType1) <- c(levels(train$BsmtFinType1), "NBsmt")
train$BsmtFinType1[which(is.na(train$BsmtFinType1))] <- "NBsmt"
levels(test$BsmtFinType1) <- c(levels(test$BsmtFinType1), "NBsmt")
test$BsmtFinType1[which(is.na(test$BsmtFinType1))] <- "NBsmt"

levels(train$BsmtFinType2) <- c(levels(train$BsmtFinType2), "NBsmt")
train$BsmtFinType2[which(is.na(train$BsmtFinType2))] <- "NBsmt"
levels(test$BsmtFinType2) <- c(levels(test$BsmtFinType2), "NBsmt")
test$BsmtFinType2[which(is.na(test$BsmtFinType2))] <- "NBsmt"

levels(train$FireplaceQu) <- c(levels(train$FireplaceQu), "NFp")
train$FireplaceQu[which(is.na(train$FireplaceQu))] <- "NFp"
levels(test$FireplaceQu) <- c(levels(test$FireplaceQu), "NFp")
test$FireplaceQu[which(is.na(test$FireplaceQu))] <- "NFp"

levels(train$GarageType) <- c(levels(train$GarageType), "NGar")
train$GarageType[which(is.na(train$GarageType))] <- "NGar"
levels(test$GarageType) <- c(levels(test$GarageType), "NGar")
test$GarageType[which(is.na(test$GarageType))] <- "NGar"

levels(train$GarageFinish) <- c(levels(train$GarageFinish), "NGar")
train$GarageFinish[which(is.na(train$GarageFinish))] <- "NGar"
levels(test$GarageFinish) <- c(levels(test$GarageFinish), "NGar")
test$GarageFinish[which(is.na(test$GarageFinish))] <- "NGar"

levels(train$GarageQual) <- c(levels(train$GarageQual), "NGar")
train$GarageQual[which(is.na(train$GarageQual))] <- "NGar"
levels(test$GarageQual) <- c(levels(test$GarageQual), "NGar")
test$GarageQual[which(is.na(test$GarageQual))] <- "NGar"

levels(train$GarageCond) <- c(levels(train$GarageCond), "NGar")
train$GarageCond[which(is.na(train$GarageCond))] <- "NGar"
levels(test$GarageCond) <- c(levels(test$GarageCond), "NGar")
test$GarageCond[which(is.na(test$GarageCond))] <- "NGar"

levels(train$PoolQC) <- c(levels(train$PoolQC), "NPool")
train$PoolQC[which(is.na(train$PoolQC))] <- "NPool"
levels(test) <- c(levels(test$PoolQC), "NPool")
test$PoolQC[which(is.na(test$PoolQC))] <- "NPool"

levels(train$Fence) <- c(levels(train$Fence), "NFen")
train$Fence[which(is.na(train$Fence))] <- "NFen"
levels(test$Fence) <- c(levels(test$Fence), "NFen")
test$Fence[which(is.na(test$Fence))] <- "NFen"

levels(train$MiscFeature) <- c(levels(train$MiscFeature), "N")
train$MiscFeature[which(is.na(train$MiscFeature))] <- "N"
levels(test$MiscFeature) <- c(levels(test$MiscFeature), "N")
test$MiscFeature[which(is.na(test$MiscFeature))] <- "N"
```

7) Missing in KitchenQual: there is a single missing value in test$KitchenQual, so we impute it with the mode of the variable, TA.
```{r}
test$KitchenQual <- replace(test$KitchenQual, is.na(test$KitchenQual), "TA")
```

8) Transformations into categorical: In some variables, like Month, we decided to transform them into categorical as only some values are possible

```{r}
# Transformation of other variables into categorical
test <- test %>%
  mutate_if(is.character, as.factor)
train <- train %>%
  mutate_if(is.character, as.factor)

test$MSSubClass = as.factor(test$MSSubClass)
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)

train$MSSubClass = as.factor(train$MSSubClass)
train$OverallQual = as.factor(train$OverallQual)
train$OverallCond = as.factor(train$OverallCond)

test$MoSold = month.name[test$MoSold]
test$MoSold = as.factor(test$MoSold)
train$MoSold = month.name[train$MoSold]
train$MoSold = as.factor(train$MoSold)
```

9) Correction of errors:  we found that "Exterior2nd" has a record of "Brk Cmn", which does not match with the data description "BrkComm". So we rename it (in order to match with "Exterior1st")

```{r}
names(test)[names(test) == "Brk Cmn"] <- "BrkComm"
```

Lastly, we define the new indexes of all types of variables after transformation.

```{r}
# Find numerical, categorical and date variables after the imputation
id_num_val = which(sapply(test, is.numeric)==TRUE)

# We won't analyze the id variable
id_num_val = as.numeric(id_num_val)[-1]; id_num_val
id_cat_val = which(sapply(test, is.factor)==TRUE)
id_cat_val = as.numeric(id_cat_val); id_cat_val
id_date_val = c(20,21,60,77,78)

# In our datasets, categorical variables are:
Categorical_val = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","BsmtFinSF2","Heating","HeatingQC","CentralAir","Electrical","LowQualFinSF","BsmtHalfBath","KitchenAbvGr","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","EnclosedPorch","X3SsnPorch","ScreenPorch","PoolArea","PoolQC","Fence","MiscFeature","SaleType","SaleCondition","MoSold")

# The numerical variables, except the target are
Numerical_val = c("LotFrontage","LotArea","YearBuilt","YearRemodAdd","MasVnrArea","BsmtFinSF1","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","FullBath","HalfBath","BedroomAbvGr","TotRmsAbvGrd","Fireplaces","GarageYrBlt","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","YrSold")

train_num = dplyr::select(train, Numerical_val)
train_cat = dplyr::select(train, Categorical_val)
```

# 1. Univariate outliers detection
First we analysed the target variable, where we found 12 severe outliers as 
this variable. Because the target variable can not be imputed we decided to 
keep those observacions and, in the remove them in the model creation in case
they are influents points. You can see all the outliers in the following plot

```{r}
sevout <- quantile(train$SalePrice,0.75,na.rm=TRUE)+3*(quantile(train$SalePrice,
        0.75,na.rm=TRUE)-quantile(train$SalePrice,0.25,na.rm=TRUE))
target_outlier <- which(train$SalePrice > sevout)

Boxplot(train$SalePrice, main = "Sale price", ylab = "Price ($)")

severe_outliers <- function(data) {
  ss <- summary(data)
  # Upper/lower severe thresholds
  utso <- as.numeric(ss[5]+3*(ss[5]-ss[2]))
  ltso <- as.numeric(ss[2]-3*(ss[5]-ss[2]))
  
  return (which((data>utso)|(data<ltso)))
}
```

Secondly, for all remaining numerical variables (26), we detected outliers and, for severe outliers, we set them to NA to impute them. This process was done automatically with a loop.

```{r, fig.show='hide'}
# Function to detect outliers
severe_outliers <- function(data) {
  ss <- summary(data)
  # Upper/lower severe thresholds
  utso <- as.numeric(ss[5]+3*(ss[5]-ss[2]))
  ltso <- as.numeric(ss[2]-3*(ss[5]-ss[2]))
  
  return (which((data>utso)|(data<ltso)))
}

# Set them to NA'n and visualize them
par(mfrow=c(1,2))

for (var in id_num_val) {
  train[severe_outliers(train[,var]),var] <- NA
  Boxplot(train[,var], ylab = names(test)[var], main = "Train")
  
  test[severe_outliers(test[,var]),var] <- NA
  Boxplot(test[,var], ylab = names(test)[var], main = "Test")
}
par(mfrow=c(1,1))
```

# 2. PCA imputation
Before the detection of outliers there was arround 1% of missing in some numerical variables (see the profiling at the annexes for more datail). After this detection, the variables that contained most missings were "GarageYrBlt" (6% in train and 5% in test), "MasVnrArea" (2% in train and 3% in test), and "OpenPorchSF"(1% in both). 

To impute, we assumed that all numerical variables had NA's that were at random and used a PCA to impute both "test" and "train" datasets. As the quartile distributions for all imputed variables are similar, as we can see in the box-plot, we conclude that the imputation was successful for all variables and created a new dataframe with the imputed values. However, for train, we found that for OpenPorchSF feature, there is a negative record. As this is the square feet for open porch area, and it cannot be negative. We suspect that it could be 0, and transformed it.

```{r, fig.show='hide', results='hide'}
# Impute
res.PCA = imputePCA (train[,id_num_val])   
str (res.PCA)
str(res.PCA$completeObs)

res.PCA.test = imputePCA (test[,id_num_val])   # impute numeric variables
str (res.PCA.test)
str(res.PCA.test$completeObs)

# Create a new dataframe
train_impute = data.frame(res.PCA$completeObs)
train_impute$SalePrice <- train$SaleP

test_impute = data.frame(res.PCA.test$completeObs)
```

```{r, fig.show='hide', results='hide'}
# Check if the imputation was successful or not: TRAIN
before_imputation = summary(train[,id_num_val])
after_imputation = summary(train_impute)

label = c('Before imputation', 'After imputation')

for (x in c(1,2,5,6,8,9,11,15,16,18,20,21,22)) {
d = data.frame(A = train[,id_num_val][x], B = train_impute[,x])
b = boxplot(d, names=label, main = names(train[,id_num_val][x]));b
}

# Transform all negative values of "OpenPorchSF" to 0's
train_impute[which(train_impute$OpenPorchSF < 0),"OpenPorchSF"] = 0
```

```{r, fig.show='hide', results='hide'}
# Check if the imputation was successful or not: TEST
before_imputation_test = summary(test[,id_num_val])
after_imputation_test = summary(test_impute)


label = c('Before imputation', 'After imputation')

for (x in c(1,2,5,6,8,9,11,15,16,18,20,21,22)) {
d = data.frame(A = test[,id_num_val][x], B = test_impute[,x])
b = boxplot(d, names=label, main = names(test[,id_num_val][x]));
b
}
```


# 3. Multivariate outliers detection
After the imputation, we decided to perform a Moutlier analysis to detect multivariate outliers. As using all numerical variables returns a singular matrix we decided to make the analysis with only the following variables: "LotFrontage", "LotArea", "YearRemodAdd", "BsmtFinSF1", "BsmtUnfSF", "GrLivArea", "Fireplaces", "GarageYrBlt", "GarageArea".

The analysis showed that there are 112 multivariate outliers in the train dataset and 115 in the test datset.

```{r}
set.seed(123) #ensure that we always get the same result in Moutlier
# Best combination of variables
id_num_val_not_corr = c(1, 2, 4, 6, 7, 11, 17,
                        18, 20)

# Analysis for train
res.mout <- Moutlier(train_impute[,id_num_val_not_corr], quantile = 0.95, plot= FALSE)

par(mfrow=c(1,2))
plot(res.mout$md, col="lightblue", pch = 19, main = 'Detection of multivariable 
outliers', xlab= 'Observation', 
     ylab ='Traditional Mahalanobis distance ')
abline(h = res.mout$cutoff, col = "red", lwd = 5, lty = 2)

plot(res.mout$rd, col="lightblue", pch = 19, xlab= 'Observation', 
     ylab ='Robust Mahalanobis distance ')
abline(h = res.mout$cutoff, col = "red", lwd = 5, lty = 2)
par(mfrow=c(1,1))

outliers = which(res.mout$md>res.mout$cutoff & res.mout$rd > res.mout$cutoff) 
length(outliers)
```

```{r}
set.seed(123) #ensure that we always get the same result in Moutlier
# Analysis for test
res.mout.test <- Moutlier(test_impute[,id_num_val_not_corr], quantile = 0.95, plot= FALSE)
par(mfrow=c(1,2))

plot(res.mout.test$md, col="lightblue", pch = 19, main = 'Detection of multivariable 
outliers', xlab= 'Observation', 
     ylab ='Traditional Mahalanobis distance ')
abline(h = res.mout.test$cutoff, col = "red", lwd = 5, lty = 2)

plot(res.mout.test$rd, col="lightblue", pch = 19, xlab= 'Observation', 
     ylab ='Robust Mahalanobis distance ')
abline(h = res.mout.test$cutoff, col = "red", lwd = 5, lty = 2)
par(mfrow=c(1,1))

outliers.test = which(res.mout.test$md>res.mout.test$cutoff & res.mout.test$rd > res.mout.test$cutoff) 
length(outliers.test)
```

# 4. EDA
The last step of the preprocessing was the exploratory data analysis. This step was done automatically using the reports generated with the "SmartEDA" library that you can find in the annexes. The reports were generated considering "train" and "test" files after imputation and just after loading them, without any transformation.

```{r, echo=FALSE}
#create_report(train_impute, output_file = "train_imputed.html")
#create_report(test_impute, output_file = "test_imputed.html")
```

The most relevant conclusions of EDA, considering all numerical values are: 

1 - "Train" and "test" datasets contains observations that follows a similar 
distribution for all variables, numerical and categorical. There are also
similarities in the % of missings and all the other summaries.

2 - Both datasets are highly unbalanced in almost all categories. 
This is specially relevant in variables like "ExterQual" or "Foundation", 
where only 2 out of 6 categories retains 86% of the accumulative probability.

3 - Numerical variables have a non normal distribution according to Shapiro–Wilk 
and Kolmogorov-Smirnov tests. This is specially relevant when modelling as
linear models requires normality.

```{r}
# Tests for normality (done in all numerical variables)
ks.test(train$LotArea, y = 'pnorm')
shapiro.test(train$LotArea)
```

# 5. Profiling and selection of categorical features
Once we have the data clean and preprocesed, we have selected the 10 most relevant
categories using the profiling of FactoMiner. More precisely, we alinised the relationship between variables in "train" datasets with "SalePrice" and selected the categorical variables with an smaller p-value. 

The variables that we selected, sorted starting with the smallest p-value, are:
OverallQual, ExterQual, BsmtQual, KitchenQual, Neighborhood, GarageFinish  
FireplaceQu, Foundation, GarageType and MSSubClass.

```{r}
# Profiling: selecting only the 10 more significative qualitative variables
res.con = condes(train, 80)         
res.con$quali[1:10,]
```

Additionally, we analysed the correlation of numerical variables with the target. According to the profile all numerical variables have a R^2 of p < 0.05 except for "YrSold". Furthermore, we have used cor.test() to test against H0="correlation between "YrSold" and "SalePrice" is 0" and we have failed to reject H0. Therefore, "YrSold" cannot be used to model "SalePrice".

```{r, results = "hide"}
res.con$quanti
res.con$category

# Test the correlation between the target and YrSold
cor.test(train$YrSold, train$SalePrice)
```

# 6. Analysis of correlation of numerical variables
Using the basic profiling of Factominer we discover that the most correlated numerical variables with the target, with more than 50 % of R^2 are: GrLivArea, GarageCars, GarageArea, TotalBsmtSF, X1stFlrSF, YearBuilt, FullBath, YearRemodAdd, GarageYrBlt and TotRmsAbvGrd.

```{r}
res.con = condes(train, 80)         
res.con$quanti
```

As variables are not normally distributed, we created the correlation matrix of all numerical variables using spearman. The result is ploted in a correlation plot, where we performed a cluster analysis to sort the variables, so that variables that are more correlated are placed closer to each other. Additionally, we decided to create 5 clusters, as we do not expect to work with a model with more than 5 numerical variables. Also, note that in this plot the target variable is not included as this analysis was already done.

The interpretation of this plot suggest that positive correlations are more common than negative, where the most important is between BsmtFullBath and BsmtFin with BsmtUnfSF. Also, there are some important positve correlarions that must be considered when making the model, for example, GarageArea is hightly correlated with GarageCars, so both variables should not be included in the same model.


```{r}
# Calculate the correlation matrix and then plot it
corr_mat = cor(train_num, method = 'spearman', use = "complete.obs")

corrplot(corr_mat, order = 'hclust', addrect = 5)
```

# 7. Preparation of data for modelling
The last step of the preprocessing was to create a new file with all the variables
that we will use to make our model. To do so, we added the 10 categorical 
variables to the imputed dataframe. The same process was done with "test" to predict the target variable using the model that we will create.

```{r}
train_impute$OverallQual <- train$OverallQual
train_impute$Neighborhood <- train$Neighborhood
train_impute$ExterQual <- train$ExterQual
train_impute$BsmtQual <- train$BsmtQual
train_impute$KitchenQual <- train$KitchenQual
train_impute$GarageFinish <- train$GarageFinish
train_impute$FireplaceQu <- train$FireplaceQu
train_impute$Foundation <- train$Foundation
train_impute$GarageType <- train$GarageType
train_impute$MSSubClass <- train$MSSubClass
train_impute$YrSold <- NULL

write.csv(train_impute, file='train_impute.csv', row.names = FALSE)
```

```{r}
test_impute$OverallQual <- test$OverallQual
test_impute$Neighborhood <- test$Neighborhood
test_impute$ExterQual <- test$ExterQual
test_impute$BsmtQual <- test$BsmtQual
test_impute$KitchenQual <- test$KitchenQual
test_impute$GarageFinish <- test$GarageFinish
test_impute$FireplaceQu <- test$FireplaceQu
test_impute$Foundation <- test$Foundation
test_impute$GarageType <- test$GarageType
test_impute$MSSubClass <- test$MSSubClass
test_impute$YrSold <- NULL

write.csv(test_impute, file='test_impute.csv', row.names = FALSE)
```

To reduce the time of computations, we have split our code in two .Rmd files. In this one, the preprocessed train dataset is found in df, while the preprocessed test database is in df_test.

```{r, include = F}
# Clean workspace
if(!is.null(dev.list())) dev.off()
rm(list = ls())
```

```{r, include = F}
# Load libraries
library(car)
library(mice)
library(dplyr) 
library(missMDA)
library(FactoMineR)
library(chemometrics)
library(DataExplorer)
library(corrplot)
library(MASS)
library(effects)
```

```{r, include=F}
# Load data
df = read.csv("train_impute.csv")
df_test = read.csv("test_impute.csv")

# Declare factors
df$OverallQual <- as.factor(df$OverallQual)
df$MSSubClass <- as.factor(df$MSSubClass)
char_var <- which(sapply(df, is.character))
df[,char_var] <- lapply(df[, char_var], as.factor)

# Declare factors
df_test$OverallQual <- as.factor(df_test$OverallQual)
df_test$MSSubClass <- as.factor(df_test$MSSubClass)
char_var <- which(sapply(df_test, is.character))
df_test[,char_var] <- lapply(df_test[, char_var], as.factor)
```


# 8. First model building
We create a first model with all the numerical variables that we selected previously.

```{r}
df_num <- df[, which(sapply(df, is.numeric))]
m0 = lm(SalePrice ~ ., data=df_num)

summary(m0)

vif(m0)
```

There are a lot of features with a vif correlation larger than 5. So, in order to reduce the amount of workload, we decided to keep those that are less than 5 and are highly correlated with our target.

```{r}
# Let's store the indices of the variables with at least one star in the lm and vif<5
id_num_star1 = c(1:5,15,17,21:23)
df_num1 <- df_num[, id_num_star1]
# And build a new model only with significance features
m1 = lm(SalePrice ~., data=df_num1)
summary(m1)
vif(m1)
# As we can observe, vif correlations are much better, all values are less than 2.
# So the next step is to check the correlation between predictors.
corr_mat <- cor(df_num1)
corrplot(corr_mat, method = "number")
```

Feature "YearBuilt" and "YearRemodAdd" are highly correlated between them, and "YearBuilt" is more correlated to our target SalePrice. Hence, we remove YearRemodAdd in the next model.

```{r}
# Building the model without "YearRemodAdd"
id_num_star2 = c(1:3,5,15,17,21:23)
df_num2 <- df_num[, id_num_star2]
m2 = lm(SalePrice ~., data=df_num2)
summary(m2)
```

Now, the most correlated variables in our model have at most a coefficient of correlation of 0.315, which in the context of real estate it is weak. We have obtained this information from https://37parallel.com/real-estate-correlation/.

```{r, results = "hide"}
Anova(m2)
```

Anova shows that all the variables we have kept are relevant.

# 9. Model analysis and iteration
First, let us plot the residuals of m2 to be able to compare them with the next iterations of the model.

```{r}
par(mfrow=c(2,2))
plot(m2)
```


We analysed if there were influential data and found 3 observations with a bigger Cook's distance than the threshold (considered as 2/sqrt(n)). Consequently, we decided to remove those observations.

```{r}
# Check the influential plot before removing the influential observation.
influencePlot(m2)

# Calculate D's threshold
D_thresh <- 2/sqrt(dim(df_num2)[1]); D_thresh

#Remove the points and fit the model again
influent <- c(1183, 692, 186)

df <- df[-influent,]
df_num <- df[, which(sapply(df, is.numeric))]
df_num2 <- df_num[, id_num_star2]
m2 = lm(SalePrice ~., data=df_num2)

influencePlot(m2)
```

Firstly, we check if there is any needed transformation with boxcox().

```{r}
boxcox(m2)
# As the lambda is greater than 0, we should apply a logarithmic transformation
# to SalePrice
m3 = lm(log(SalePrice)~., data=df_num2)
summary(m3)
```

Compared with m2, adjusted R-squared has increased about 4%.

We will proceed now with the study of possible variable transformations. We'll assign 10^(-6) to all cells equal to 0 to be able to use boxTidwell() without altering too much the model

```{r}
df_num2 = replace(df_num2, df_num2 == 0, 1e-6)
summary(df_num2)

boxTidwell(log(SalePrice) ~ LotArea+YearBuilt+MasVnrArea, data = df_num2)
# We should apply sqrt(LotArea). YearBuilt's lambda is too large, so it would be
# difficult to interpret the model using it. MasVnrArea has a too large p-value,
# so we cannot reject the null hypothesis that its lambda = 1.
boxTidwell(log(SalePrice)~LotFrontage, data = df_num2)
# Too small lambda
boxTidwell(log(SalePrice)~BedroomAbvGr, data = df_num2)
# Too large p-value
boxTidwell(log(SalePrice)~Fireplaces, data =df_num2)
# We apply log() to Fireplaces
boxTidwell(log(SalePrice)~WoodDeckSF, data = df_num2)
# We apply sqrt() to WoodDeckSF
boxTidwell(log(SalePrice)~OpenPorchSF, data = df_num2)
# Too small lambda
```

Using the boxTidwell method, the transformation below can be applied to m4.

```{r}
m4 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea+
          BedroomAbvGr+log(Fireplaces)+sqrt(WoodDeckSF)+OpenPorchSF,
        data=df_num2)
summary(m4)
```

Adjusted R-squared has increased slightly. Since we cannot find a significant improvement, we will compare m3 and m4 with a more advanced tool, the BIC.

```{r}
BIC(m3, m4)
```

The overall improvement of applying all transformations simultaneously is small, so we decided to check different combinations to find a better result.

```{r}
m5 = lm(log(SalePrice) ~ LotFrontage+LotArea+YearBuilt+MasVnrArea+
          BedroomAbvGr+log(Fireplaces)+sqrt(WoodDeckSF)+OpenPorchSF,data=df_num2)
m6 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea+
          BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF,data=df_num2)
m7 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea
        +BedroomAbvGr+log(Fireplaces)+WoodDeckSF+OpenPorchSF,data=df_num2)
m8 = lm(log(SalePrice)~LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea+
          BedroomAbvGr+Fireplaces+WoodDeckSF+OpenPorchSF, data=df_num2)
m9 = lm(log(SalePrice)~LotFrontage+LotArea+YearBuilt+MasVnrArea+BedroomAbvGr+
          log(Fireplaces)+WoodDeckSF+OpenPorchSF, data=df_num2)
m10 = lm(log(SalePrice)~LotFrontage+LotArea+YearBuilt+MasVnrArea+BedroomAbvGr+
           Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF, data=df_num2)
BIC(m4,m5,m6,m7,m8,m9,m10)
```

The best model is m6, that only applies sqrt() to LotArea and WoodDeckSF. For this model we have compared the distribution of residuals and realized that it is very similar to the original model.

```{r}
par(mfrow=c(2,2))
m11 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea
         +BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF,data=df_num)
BIC(m3,m11)
plot(m11)
```

# 10. Adding Factors to the numerical model
We followed an heuristic approach when we added factors to the model. As there was an important amount of numeric variables, we tried to add factor variables one by one. We started with the predictor most correlated with the target and continued in decreasing order. To test the improvement of the model's forecasting capability we analysed its BIC and R^2. Moreover, Anova() and step() methods suggest whether some predictors should be removed.

The results of the code of this section are very long and repetitive, so we hide them in the report.

```{r, results = "hide"}
m12 = lm(log(SalePrice)~LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea
         +BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual, data=df)
BIC(m11,m12)
Anova(m12)
step(m12, k = log(nrow(df)))
```

Comparing m11 and m12, there was a huge improvement in terms of BIC and Adjusted R-squared, as we expected.

The Anova test indicates that LotFrontage loses its significance once we add OverallQual, and the step method suggests to remove it.

```{r, results = "hide"}
m12.1 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr
           +Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual, data=df)
summary(m12.1)
BIC(m10,m12,m12.1)
```

After removing LotFrontage, although R^2 didn't change, BIC increased because we used less variables and avoided overfitting.

Next, in m13, we have added ExterQual.

```{r, results = "hide"}
m13 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
           Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+ExterQual, data=df)
summary(m13)
BIC(m13,m12.1)
Anova(m13)
step(m13, k = log(nrow(df)))
```

All parameters show that it is correct to add ExterQual, so we continue by adding BsmtQual to the model.

```{r, results = "hide"}
m14 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
           Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+ExterQual+
           BsmtQual, data=df)
summary(m14)
BIC(m14,m13)
Anova(m14)
step(m14, k = log(nrow(df)))
```

After this, we add KitcheQual. 

```{r, results = "hide"}
m15 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
           Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+ExterQual+
           BsmtQual+KitchenQual, data=df); summary(m15)
BIC(m15,m14)
Anova(m15)
step(m15, k = log(nrow(df)))
```

The step method shows that ExterQual, after adding the KitchenQual, has lost significance and suggests to remove it. Indeed, BIC improves afterwards.

```{r, results = "hide"}
m15.1 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
             Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+BsmtQual+
             KitchenQual, data=df); summary(m15.1)
BIC(m15.1,m15)
Anova(m15.1)
step(m15.1, k = log(nrow(df)))
```

Adding Neighbourhood to the model.

```{r, results = "hide"}
m16.1 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
             Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+BsmtQual+
             KitchenQual+Neighborhood, data=df); summary(m16.1)
BIC(m16.1,m15.1)
Anova(m16.1)
step(m16.1, k = log(nrow(df)))
```

Adding GarageFinish.

```{r, results = "hide"}
m16.2 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
             Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+BsmtQual+
             KitchenQual+Neighborhood+GarageFinish, data=df); summary(m16.2)
BIC(m16.2,m16.1)
Anova(m16.2)
step(m16.2, k = log(nrow(df)))
```

Adding FireplaceQu.

```{r, results = "hide"}
m16.3 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
             Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+BsmtQual+
             KitchenQual+Neighborhood+GarageFinish+FireplaceQu, data=df)
summary(m16.3)
BIC(m16.3,m16.2,m16.1)
Anova(m16.3)
step(m16.3, k = log(nrow(df)))
```

In m16.3, FireplaceQu's coefficient has a p-value larger than 0.05 and, indeed, step() suggests to remove it from the model. Hence, we stop adding new categorical variables.


# 11. Checking possible Interactions
YearBuilt and OverallQual intuitively should interact because of inflation. Indeed, all variables could interact with YearBuilt, but OverallQual summarizes them.

We will also hide the output of this section's chunks to shorten the report.

```{r, results = "hide"}
m17 = lm(log(SalePrice)~sqrt(LotArea)+MasVnrArea+
          BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+YearBuilt*
           OverallQual+BsmtQual+KitchenQual+Neighborhood+GarageFinish, data=df)
summary(m17)
BIC(m17,m16.2)
Anova(m17)
step(m17, k = log(nrow(df)))
```

2. LotArea and YearBuilt should interact as well because of inflation.

```{r, results = "hide"}
m18 = lm(log(SalePrice)~MasVnrArea+
          BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+YearBuilt*
           OverallQual+sqrt(LotArea)*YearBuilt+OverallQual+BsmtQual+KitchenQual
         +Neighborhood+GarageFinish, data=df); summary(m18)
BIC(m18,m17,m16.2)
Anova(m18)
step(m18, k = log(nrow(df)))
```

Any of these interactions have improved much the model, so we won't keep them. No other interaction would make sense, so we will not try anymore.

Our final model is m16.2. That is, log(SalePrice) ~ sqrt(LotArea) + YearBuilt + MasVnrArea + BedroomAbvGr + Fireplaces + sqrt(WoodDeckSF) + OpenPorchSF + OverallQual + BsmtQual + KitchenQual + Neighborhood + GarageFinish. Its adjusted R^2 is 0.8195 and its BIC is about -972.

```{r}
summary(m16.2)
BIC(m16.2, m11, m1)
```


# 12. Model validation
We predict the SalePrice on the test dataset and compare its distribution with the original one in train.

```{r}
predicted_values = predict.lm(m16.2, df_test, se.fit=TRUE,
                              interval="prediction", level=0.95)
test_price = exp(predicted_values$fit)
```

```{r}
par(mfrow=c(1,2))
hist(test_price[,1], main = "Predicted Sale Price on Test",
     xlab =  "Predicted test$SalePrice")
hist(df$SalePrice, main = "Sale Price on Train",
     xlab = "Real train$SalePrice")
```

```{r}
par(mfrow=c(1,1))
plot(density(test_price[,1]), col="red", main = "Density of SalePrice",
     xlab = "SalePrice")
lines(density(df$SalePrice), col="blue")
legend("topright",fill = c("red", "blue"), c("Predicted on Test","Real on Train"))
```

As can be seen in the previous plots, the real and the predicted distributions of SalePrice are similar, but not identical. This was exactly our goal, since both test and train come from the same population and we wanted to avoid overfitting.

```{r}
marginalModelPlots(m16.2, id=list(n=0))
```

```{r}
residualPlots( m16.2, id=list(n=0))
```

In general, using the marginal model plots, we can see that the residuals distribution for most variables are close to 0. However, sqrt(LotArea) seems to have bad residuals in marginalModelPlots(), but not in residualPlots(). This could simply mean the first method doesn't properly represent the residuals of this variable. As for categorical variables, all errors are close to 0, except for the level "VBad" of OverallQual, which is due to the fact that it contains few individuals.

```{r}
ks_test_result <- ks.test(test_price[,1], df$SalePrice)
ks_test_result
```

The Kolmogorov-Smirnov test shows that predicted and real distributions of SalePrice should be assumed to be different.

Finally, we will check the normality of the residuals.

```{r}
par(mfrow=c(2,2))
plot(m16.2)
shapiro.test(m16.2$residuals)
```

Residuals don't follow a normal distribution, so the model won't give very accurate results. Nevertheless, we are happy with our results, so we will not apply any more changes.

# 13. Model interpretation

First, let us remember the model we have obtained:  log(SalePrice) ~ sqrt(LotArea) + YearBuilt + MasVnrArea + BedroomAbvGr + Fireplaces + sqrt(WoodDeckSF) + OpenPorchSF + 
OverallQual + BsmtQual + KitchenQual + Neighborhood + GarageFinish.

We are modeling the logarithm of SalePrice. That is, an increase of one unit in any of the predictors (except for LotArea and WoodDeckSF) causes the price of the sale to be multiplied by the number e. All the predictors we are using make sense intuitively: the area of the lot, the masonry veneer, the wood deck and the open porch, the amount of bedrooms above ground and fireplaces, the overall quality but also that of the basement and the kitchen, the interior finish of the garage, the dwelling neighborhood's wealth and the year it was built. 
The area of the lot and the wood deck appear with an exponent of 1/2 in the model, which means that the slope of their contribution to log(SalePrice) is lower than that of the other terms for values larger than 1/4.

In total, our model predictors are composed of 7 numerical features and 5 categorical variables, with three transformations and no interactions.