levels(train$BsmtCond) <- c(levels(train$BsmtCond), "NBsmt")
train$BsmtCond[which(is.na(train$BsmtCond))] <- "NBsmt"
levels(test$BsmtCond) <- c(levels(test$BsmtCond), "NBsmt")
test$BsmtCond[which(is.na(test$BsmtCond))] <- "NBsmt"
levels(train$BsmtExposure) <- c(levels(train$BsmtExposure), "NBsmt")
train$BsmtExposure[which(is.na(train$BsmtExposure))] <- "NBsmt"
levels(test$BsmtExposure) <- c(levels(test$BsmtExposure), "NBsmt")
test$BsmtExposure[which(is.na(test$BsmtExposure))] <- "NBsmt"
levels(train$BsmtFinType1) <- c(levels(train$BsmtFinType1), "NBsmt")
train$BsmtFinType1[which(is.na(train$BsmtFinType1))] <- "NBsmt"
levels(test$BsmtFinType1) <- c(levels(test$BsmtFinType1), "NBsmt")
test$BsmtFinType1[which(is.na(test$BsmtFinType1))] <- "NBsmt"
levels(train$BsmtFinType2) <- c(levels(train$BsmtFinType2), "NBsmt")
train$BsmtFinType2[which(is.na(train$BsmtFinType2))] <- "NBsmt"
levels(test$BsmtFinType2) <- c(levels(test$BsmtFinType2), "NBsmt")
test$BsmtFinType2[which(is.na(test$BsmtFinType2))] <- "NBsmt"
levels(train$FireplaceQu) <- c(levels(train$FireplaceQu), "NFp")
train$FireplaceQu[which(is.na(train$FireplaceQu))] <- "NFp"
levels(test$FireplaceQu) <- c(levels(test$FireplaceQu), "NFp")
test$FireplaceQu[which(is.na(test$FireplaceQu))] <- "NFp"
levels(train$GarageType) <- c(levels(train$GarageType), "NGar")
train$GarageType[which(is.na(train$GarageType))] <- "NGar"
levels(test$GarageType) <- c(levels(test$GarageType), "NGar")
test$GarageType[which(is.na(test$GarageType))] <- "NGar"
levels(train$GarageFinish) <- c(levels(train$GarageFinish), "NGar")
train$GarageFinish[which(is.na(train$GarageFinish))] <- "NGar"
levels(test$GarageFinish) <- c(levels(test$GarageFinish), "NGar")
test$GarageFinish[which(is.na(test$GarageFinish))] <- "NGar"
levels(train$GarageQual) <- c(levels(train$GarageQual), "NGar")
train$GarageQual[which(is.na(train$GarageQual))] <- "NGar"
levels(test$GarageQual) <- c(levels(test$GarageQual), "NGar")
test$GarageQual[which(is.na(test$GarageQual))] <- "NGar"
levels(train$GarageCond) <- c(levels(train$GarageCond), "NGar")
train$GarageCond[which(is.na(train$GarageCond))] <- "NGar"
levels(test$GarageCond) <- c(levels(test$GarageCond), "NGar")
test$GarageCond[which(is.na(test$GarageCond))] <- "NGar"
levels(train$PoolQC) <- c(levels(train$PoolQC), "NPool")
train$PoolQC[which(is.na(train$PoolQC))] <- "NPool"
levels(test) <- c(levels(test$PoolQC), "NPool")
test$PoolQC[which(is.na(test$PoolQC))] <- "NPool"
levels(train$Fence) <- c(levels(train$Fence), "NFen")
train$Fence[which(is.na(train$Fence))] <- "NFen"
levels(test$Fence) <- c(levels(test$Fence), "NFen")
test$Fence[which(is.na(test$Fence))] <- "NFen"
levels(train$MiscFeature) <- c(levels(train$MiscFeature), "N")
train$MiscFeature[which(is.na(train$MiscFeature))] <- "N"
levels(test$MiscFeature) <- c(levels(test$MiscFeature), "N")
test$MiscFeature[which(is.na(test$MiscFeature))] <- "N"
# Chunk 11
test$KitchenQual <- replace(test$KitchenQual, is.na(test$KitchenQual), "TA")
# Chunk 12
# Transformation of other variables into categorical
test <- test %>%
mutate_if(is.character, as.factor)
train <- train %>%
mutate_if(is.character, as.factor)
test$MSSubClass = as.factor(test$MSSubClass)
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)
train$MSSubClass = as.factor(train$MSSubClass)
train$OverallQual = as.factor(train$OverallQual)
train$OverallCond = as.factor(train$OverallCond)
test$MoSold = month.name[test$MoSold]
test$MoSold = as.factor(test$MoSold)
train$MoSold = month.name[train$MoSold]
train$MoSold = as.factor(train$MoSold)
# Chunk 13
names(test)[names(test) == "Brk Cmn"] <- "BrkComm"
# Chunk 14
# Find numerical, categorical and date variables after the imputation
id_num_val = which(sapply(test, is.numeric)==TRUE)
# We won't analyze the id variable
id_num_val = as.numeric(id_num_val)[-1]; id_num_val
id_cat_val = which(sapply(test, is.factor)==TRUE)
id_cat_val = as.numeric(id_cat_val); id_cat_val
id_date_val = c(20,21,60,77,78)
# In our datasets, categorical variables are:
Categorical_val = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","BsmtFinSF2","Heating","HeatingQC","CentralAir","Electrical","LowQualFinSF","BsmtHalfBath","KitchenAbvGr","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","EnclosedPorch","X3SsnPorch","ScreenPorch","PoolArea","PoolQC","Fence","MiscFeature","SaleType","SaleCondition","MoSold")
# The numerical variables, except the target are
Numerical_val = c("LotFrontage","LotArea","YearBuilt","YearRemodAdd","MasVnrArea","BsmtFinSF1","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","FullBath","HalfBath","BedroomAbvGr","TotRmsAbvGrd","Fireplaces","GarageYrBlt","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","YrSold")
train_num = dplyr::select(train, Numerical_val)
train_cat = dplyr::select(train, Categorical_val)
# Chunk 15
sevout <- quantile(train$SalePrice,0.75,na.rm=TRUE)+3*(quantile(train$SalePrice,
0.75,na.rm=TRUE)-quantile(train$SalePrice,0.25,na.rm=TRUE))
target_outlier <- which(train$SalePrice > sevout)
Boxplot(train$SalePrice, main = "Sale price", ylab = "Price ($)")
severe_outliers <- function(data) {
ss <- summary(data)
# Upper/lower severe thresholds
utso <- as.numeric(ss[5]+3*(ss[5]-ss[2]))
ltso <- as.numeric(ss[2]-3*(ss[5]-ss[2]))
return (which((data>utso)|(data<ltso)))
}
# Chunk 16
# Function to detect outliers
severe_outliers <- function(data) {
ss <- summary(data)
# Upper/lower severe thresholds
utso <- as.numeric(ss[5]+3*(ss[5]-ss[2]))
ltso <- as.numeric(ss[2]-3*(ss[5]-ss[2]))
return (which((data>utso)|(data<ltso)))
}
# Set them to NA'n and visualize them
par(mfrow=c(1,2))
for (var in id_num_val) {
train[severe_outliers(train[,var]),var] <- NA
Boxplot(train[,var], ylab = names(test)[var], main = "Train")
test[severe_outliers(test[,var]),var] <- NA
Boxplot(test[,var], ylab = names(test)[var], main = "Test")
}
par(mfrow=c(1,1))
# Chunk 17
# Impute
res.PCA = imputePCA (train[,id_num_val])
str (res.PCA)
str(res.PCA$completeObs)
res.PCA.test = imputePCA (test[,id_num_val])   # impute numeric variables
str (res.PCA.test)
str(res.PCA.test$completeObs)
# Create a new dataframe
train_impute = data.frame(res.PCA$completeObs)
train_impute$SalePrice <- train$SaleP
test_impute = data.frame(res.PCA.test$completeObs)
# Chunk 18
# Check if the imputation was successful or not: TRAIN
before_imputation = summary(train[,id_num_val])
after_imputation = summary(train_impute)
label = c('Before imputation', 'After imputation')
for (x in c(1,2,5,6,8,9,11,15,16,18,20,21,22)) {
d = data.frame(A = train[,id_num_val][x], B = train_impute[,x])
b = boxplot(d, names=label, main = names(train[,id_num_val][x]));b
}
# Transform all negative values of "OpenPorchSF" to 0's
train_impute[which(train_impute$OpenPorchSF < 0),"OpenPorchSF"] = 0
# Chunk 19
# Check if the imputation was successful or not: TEST
before_imputation_test = summary(test[,id_num_val])
after_imputation_test = summary(test_impute)
label = c('Before imputation', 'After imputation')
for (x in c(1,2,5,6,8,9,11,15,16,18,20,21,22)) {
d = data.frame(A = test[,id_num_val][x], B = test_impute[,x])
b = boxplot(d, names=label, main = names(test[,id_num_val][x]));
b
}
# Chunk 20
set.seed(123) #ensure that we always get the same result in Moutlier
# Best combination of variables
id_num_val_not_corr = c(1, 2, 4, 6, 7, 11, 17,
18, 20)
# Analysis for train
res.mout <- Moutlier(train_impute[,id_num_val_not_corr], quantile = 0.95, plot= FALSE)
par(mfrow=c(1,2))
plot(res.mout$md, col="lightblue", pch = 19, main = 'Detection of multivariable
outliers', xlab= 'Observation',
ylab ='Traditional Mahalanobis distance ')
abline(h = res.mout$cutoff, col = "red", lwd = 5, lty = 2)
plot(res.mout$rd, col="lightblue", pch = 19, xlab= 'Observation',
ylab ='Robust Mahalanobis distance ')
abline(h = res.mout$cutoff, col = "red", lwd = 5, lty = 2)
par(mfrow=c(1,1))
outliers = which(res.mout$md>res.mout$cutoff & res.mout$rd > res.mout$cutoff)
length(outliers)
# Chunk 21
set.seed(123) #ensure that we always get the same result in Moutlier
# Analysis for test
res.mout.test <- Moutlier(test_impute[,id_num_val_not_corr], quantile = 0.95, plot= FALSE)
par(mfrow=c(1,2))
plot(res.mout.test$md, col="lightblue", pch = 19, main = 'Detection of multivariable
outliers', xlab= 'Observation',
ylab ='Traditional Mahalanobis distance ')
abline(h = res.mout.test$cutoff, col = "red", lwd = 5, lty = 2)
plot(res.mout.test$rd, col="lightblue", pch = 19, xlab= 'Observation',
ylab ='Robust Mahalanobis distance ')
abline(h = res.mout.test$cutoff, col = "red", lwd = 5, lty = 2)
par(mfrow=c(1,1))
outliers.test = which(res.mout.test$md>res.mout.test$cutoff & res.mout.test$rd > res.mout.test$cutoff)
length(outliers.test)
# Chunk 22
#create_report(train_impute, output_file = "train_imputed.html")
#create_report(test_impute, output_file = "test_imputed.html")
# Chunk 23
# Tests for normality (done in all numerical variables)
ks.test(train$LotArea, y = 'pnorm')
shapiro.test(train$LotArea)
# Chunk 24
# Profiling: selecting only the 10 more significative qualitative variables
res.con = condes(train, 80)
res.con$quali[1:10,]
res.con$quanti
res.con$category
res.con = condes(train, 80)
res.con$quanti
# Chunk 1
# Clean workspace
if(!is.null(dev.list())) dev.off()
rm(list = ls())
# Chunk 2
# Load libraries
library(car)
library(mice)
library(dplyr)
library(missMDA)
library(FactoMineR)
library(chemometrics)
library(DataExplorer)
library(corrplot)
library(MASS)
library(effects)
# Chunk 3
# Load data
df = read.csv("train_impute.csv")
df_test = read.csv("test_impute.csv")
# Declare factors
df$OverallQual <- as.factor(df$OverallQual)
df$MSSubClass <- as.factor(df$MSSubClass)
char_var <- which(sapply(df, is.character))
df[,char_var] <- lapply(df[, char_var], as.factor)
# Declare factors
df_test$OverallQual <- as.factor(df_test$OverallQual)
df_test$MSSubClass <- as.factor(df_test$MSSubClass)
char_var <- which(sapply(df_test, is.character))
df_test[,char_var] <- lapply(df_test[, char_var], as.factor)
# Chunk 4
df_num <- df[, which(sapply(df, is.numeric))]
m0 = lm(SalePrice ~ ., data=df_num)
summary(m0)
vif(m0)
# Chunk 5
# Let's store the indices of the variables with at least one star in the lm and vif<5
id_num_star1 = c(1:5,15,17,21:23)
df_num1 <- df_num[, id_num_star1]
# And build a new model only with significance features
m1 = lm(SalePrice ~., data=df_num1)
summary(m1)
vif(m1)
# As we can observe, vif correlations are much better, all values are less than 2.
# So the next step is to check the correlation between predictors.
corr_mat <- cor(df_num1)
corrplot(corr_mat, method = "number")
# Chunk 6
# Building the model without "YearRemodAdd"
id_num_star2 = c(1:3,5,15,17,21:23)
df_num2 <- df_num[, id_num_star2]
m2 = lm(SalePrice ~., data=df_num2)
summary(m2)
# Chunk 7
Anova(m2)
# Chunk 8
par(mfrow=c(2,2))
plot(m2)
# Chunk 9
# Check the influential plot before removing the influential observation.
influencePlot(m2)
# Calculate D's threshold
D_thresh <- 2/sqrt(dim(df_num2)[1]); D_thresh
#Remove the points and fit the model again
influent <- c(1183, 692, 186)
df <- df[-influent,]
df_num <- df[, which(sapply(df, is.numeric))]
df_num2 <- df_num[, id_num_star2]
m2 = lm(SalePrice ~., data=df_num2)
influencePlot(m2)
# Chunk 10
boxcox(m2)
# As the lambda is greater than 0, we should apply a logarithmic transformation
# to SalePrice
m3 = lm(log(SalePrice)~., data=df_num2)
summary(m3)
# Chunk 11
df_num2 = replace(df_num2, df_num2 == 0, 1e-6)
summary(df_num2)
boxTidwell(log(SalePrice) ~ LotArea+YearBuilt+MasVnrArea, data = df_num2)
# We should apply sqrt(LotArea). YearBuilt's lambda is too large, so it would be
# difficult to interpret the model using it. MasVnrArea has a too large p-value,
# so we cannot reject the null hypothesis that its lambda = 1.
boxTidwell(log(SalePrice)~LotFrontage, data = df_num2)
# Too small lambda
boxTidwell(log(SalePrice)~BedroomAbvGr, data = df_num2)
# Too large p-value
boxTidwell(log(SalePrice)~Fireplaces, data =df_num2)
# We apply log() to Fireplaces
boxTidwell(log(SalePrice)~WoodDeckSF, data = df_num2)
# We apply sqrt() to WoodDeckSF
boxTidwell(log(SalePrice)~OpenPorchSF, data = df_num2)
# Too small lambda
# Chunk 12
m4 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea+
BedroomAbvGr+log(Fireplaces)+sqrt(WoodDeckSF)+OpenPorchSF,
data=df_num2)
summary(m4)
# Chunk 13
BIC(m3, m4)
m5 = lm(log(SalePrice) ~ LotFrontage+LotArea+YearBuilt+MasVnrArea+
BedroomAbvGr+log(Fireplaces)+sqrt(WoodDeckSF)+OpenPorchSF,data=df_num2)
m6 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea+
BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF,data=df_num2)
m7 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea
+BedroomAbvGr+log(Fireplaces)+WoodDeckSF+OpenPorchSF,data=df_num2)
m8 = lm(log(SalePrice)~LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea+
BedroomAbvGr+Fireplaces+WoodDeckSF+OpenPorchSF, data=df_num2)
m9 = lm(log(SalePrice)~LotFrontage+LotArea+YearBuilt+MasVnrArea+BedroomAbvGr+
log(Fireplaces)+WoodDeckSF+OpenPorchSF, data=df_num2)
m10 = lm(log(SalePrice)~LotFrontage+LotArea+YearBuilt+MasVnrArea+BedroomAbvGr+
Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF, data=df_num2)
BIC(m4,m5,m6,m7,m8,m9,m10)
par(mfrow=c(2,2))
m11 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea
+BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF,data=df_num)
BIC(m3,m11)
plot(m11)
m12 = lm(log(SalePrice)~LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea
+BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual, data=df)
# Chunk 1
# Clean workspace
if(!is.null(dev.list())) dev.off()
rm(list = ls())
# Chunk 2
# Load libraries
library(car)
library(mice)
library(dplyr)
library(missMDA)
library(FactoMineR)
library(chemometrics)
library(DataExplorer)
library(corrplot)
library(MASS)
library(effects)
# Chunk 3
# Load data
df = read.csv("train_impute.csv")
df_test = read.csv("test_impute.csv")
# Declare factors
df$OverallQual <- as.factor(df$OverallQual)
df$MSSubClass <- as.factor(df$MSSubClass)
char_var <- which(sapply(df, is.character))
df[,char_var] <- lapply(df[, char_var], as.factor)
# Declare factors
df_test$OverallQual <- as.factor(df_test$OverallQual)
df_test$MSSubClass <- as.factor(df_test$MSSubClass)
char_var <- which(sapply(df_test, is.character))
df_test[,char_var] <- lapply(df_test[, char_var], as.factor)
# Chunk 4
df_num <- df[, which(sapply(df, is.numeric))]
m0 = lm(SalePrice ~ ., data=df_num)
summary(m0)
vif(m0)
# Chunk 5
# Let's store the indices of the variables with at least one star in the lm and vif<5
id_num_star1 = c(1:5,15,17,21:23)
df_num1 <- df_num[, id_num_star1]
# And build a new model only with significance features
m1 = lm(SalePrice ~., data=df_num1)
summary(m1)
vif(m1)
# As we can observe, vif correlations are much better, all values are less than 2.
# So the next step is to check the correlation between predictors.
corr_mat <- cor(df_num1)
corrplot(corr_mat, method = "number")
# Chunk 6
# Building the model without "YearRemodAdd"
id_num_star2 = c(1:3,5,15,17,21:23)
df_num2 <- df_num[, id_num_star2]
m2 = lm(SalePrice ~., data=df_num2)
summary(m2)
# Chunk 7
Anova(m2)
# Chunk 8
par(mfrow=c(2,2))
plot(m2)
# Chunk 9
# Check the influential plot before removing the influential observation.
influencePlot(m2)
# Calculate D's threshold
D_thresh <- 2/sqrt(dim(df_num2)[1]); D_thresh
#Remove the points and fit the model again
influent <- c(1183, 692, 186)
df <- df[-influent,]
df_num <- df[, which(sapply(df, is.numeric))]
df_num2 <- df_num[, id_num_star2]
m2 = lm(SalePrice ~., data=df_num2)
influencePlot(m2)
# Chunk 10
boxcox(m2)
# As the lambda is greater than 0, we should apply a logarithmic transformation
# to SalePrice
m3 = lm(log(SalePrice)~., data=df_num2)
summary(m3)
# Chunk 11
df_num2 = replace(df_num2, df_num2 == 0, 1e-6)
summary(df_num2)
boxTidwell(log(SalePrice) ~ LotArea+YearBuilt+MasVnrArea, data = df_num2)
# We should apply sqrt(LotArea). YearBuilt's lambda is too large, so it would be
# difficult to interpret the model using it. MasVnrArea has a too large p-value,
# so we cannot reject the null hypothesis that its lambda = 1.
boxTidwell(log(SalePrice)~LotFrontage, data = df_num2)
# Too small lambda
boxTidwell(log(SalePrice)~BedroomAbvGr, data = df_num2)
# Too large p-value
boxTidwell(log(SalePrice)~Fireplaces, data =df_num2)
# We apply log() to Fireplaces
boxTidwell(log(SalePrice)~WoodDeckSF, data = df_num2)
# We apply sqrt() to WoodDeckSF
boxTidwell(log(SalePrice)~OpenPorchSF, data = df_num2)
# Too small lambda
# Chunk 12
m4 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea+
BedroomAbvGr+log(Fireplaces)+sqrt(WoodDeckSF)+OpenPorchSF,
data=df_num2)
summary(m4)
# Chunk 13
BIC(m3, m4)
# Chunk 14
m5 = lm(log(SalePrice) ~ LotFrontage+LotArea+YearBuilt+MasVnrArea+
BedroomAbvGr+log(Fireplaces)+sqrt(WoodDeckSF)+OpenPorchSF,data=df_num2)
m6 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea+
BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF,data=df_num2)
m7 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea
+BedroomAbvGr+log(Fireplaces)+WoodDeckSF+OpenPorchSF,data=df_num2)
m8 = lm(log(SalePrice)~LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea+
BedroomAbvGr+Fireplaces+WoodDeckSF+OpenPorchSF, data=df_num2)
m9 = lm(log(SalePrice)~LotFrontage+LotArea+YearBuilt+MasVnrArea+BedroomAbvGr+
log(Fireplaces)+WoodDeckSF+OpenPorchSF, data=df_num2)
m10 = lm(log(SalePrice)~LotFrontage+LotArea+YearBuilt+MasVnrArea+BedroomAbvGr+
Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF, data=df_num2)
BIC(m4,m5,m6,m7,m8,m9,m10)
# Chunk 15
par(mfrow=c(2,2))
m11 = lm(log(SalePrice) ~ LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea
+BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF,data=df_num)
BIC(m3,m11)
plot(m11)
# Chunk 16
m12 = lm(log(SalePrice)~LotFrontage+sqrt(LotArea)+YearBuilt+MasVnrArea
+BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual, data=df)
BIC(m11,m12)
Anova(m12)
step(m12, k = log(nrow(df)))
m13 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+ExterQual, data=df)
summary(m13)
BIC(m13,m12.1)
m13 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+ExterQual, data=df)
summary(m13)
BIC(m13,m12.1)
m14 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+ExterQual+BsmtQual, data=df)
summary(m14)
BIC(m14,m13)
Anova(m14)
step(m14, k = log(nrow(df)))
m14 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+ExterQual+
BsmtQual, data=df)
summary(m14)
BIC(m14,m13)
Anova(m14)
step(m14, k = log(nrow(df)))
m15 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+ExterQual+
BsmtQual+KitchenQual, data=df); summary(m15)
BIC(m15,m14)
Anova(m15)
step(m15, k = log(nrow(df)))
m15.1 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+BsmtQual+
KitchenQual, data=df); summary(m15.1)
BIC(m15.1,m15)
Anova(m15.1)
step(m15.1, k = log(nrow(df)))
m16.1 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+BsmtQual+
KitchenQual+Neighborhood, data=df); summary(m16.1)
BIC(m16.1,m15.1)
Anova(m16.1)
step(m16.1, k = log(nrow(df)))
m16.3 = lm(log(SalePrice)~sqrt(LotArea)+YearBuilt+MasVnrArea+BedroomAbvGr+
Fireplaces+sqrt(WoodDeckSF)+OpenPorchSF+OverallQual+BsmtQual+
KitchenQual+Neighborhood+GarageFinish+FireplaceQu, data=df)
summary(m16.3)
BIC(m16.3,m16.2,m16.1)
# Delete any existing object
if(!is.null(dev.list())) dev.off()
rm(list = ls())
library(car)
library(mice)
library(dplyr)
library(missMDA)
library(FactoMineR)
library(chemometrics)
library(DataExplorer)
library(corrplot)
library(DataExplorer)
library(MASS)
library(effects)
train = read.csv("train.csv")
test = read.csv("test.csv")
#Create EDA report before any data preparation
#create_report(train, output_format = "pdf_document", output_file = "train.pdf")
#create_report(test, output_format = "pdf_document", output_file = "test.pdf")
Categorical_val = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC","CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature","SaleType","SaleCondition", "MoSold")
Numerical_val = c("LotFrontage","LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal","YearBuilt","YearRemodAdd","GarageYrBlt","YrSold")
Date_val = c("YearBuilt","YearRemodAdd","GarageYrBlt","MoSold","YrSold")
# Identify variables susceptible to be transformed into categorical
sapply(dplyr::select(train, Numerical_val), table)
sapply(dplyr::select(train, Categorical_val), table)
sapply(dplyr::select(train, Date_val), table)
# As we can see there are an important number of Nan
# PoolArea: 99% missings
length(which(train$PoolArea > 0))/dim(train)[1]*100
length(which(test$PoolArea > 0))/dim(test)[1]*100
