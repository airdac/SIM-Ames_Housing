train$OverallCond = as.factor(train$OverallCond)
# Assumption 5.
names(test)[names(test) == "Brk Cmn"] <- "BrkComm"
# Assumption 6.
test <- test %>%
mutate_if(is.character, as.factor)
train <- train %>%
mutate_if(is.character, as.factor)
# Chunk 8
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
# Chunk 9
# Multivariate outlier Analysis
# Chunk 10
# PCA imputation
# In this section we'll Performance PCA to impute the missing data
# Chunk 11
# Categorical feature selection
# Once we have the data clean and preprocesed, we'll get into the selection of the categorical feature, leaving only with 10 of then.
table(test$MSSubClass)
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
Boxplot(test)
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
Boxplot(test_num)
Boxplot(test_num$LotFrontage)
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
Boxplot(test_num)
Boxplot(test_num$LotFrontage)
Boxplot(test_num$LotArea)
Boxplot(test_num$MasVnrArea)
Boxplot(test_num$BsmtFinSF1)
Boxplot(test_num$BsmtFinSF2)
Boxplot(test_num$BsmtUnfSF)
Boxplot(test_num$X1stFlrSF)
Boxplot(test_num$X2ndFlrSF)
Boxplot(test_num$LowQualFinSF)
Categorical_val = c('MSSubClass',"MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC","CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature","SaleType","SaleCondition", "LowQualFinSF", "PoolArea")
Numerical_val = c("LotFrontage","LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal")
# Find the numerical sets and categorical sets
test_num = select(test, Numerical_val); summary(test_num)
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
Boxplot(test_num)
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(test_num)
severe_out
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(test_num)
severe_out
severe_out
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(test_num)
severe_out
# Load the data
if(!is.null(dev.list())) dev.off()
rm(list = ls())
test = read.csv("test.csv")
train = read.csv("train.csv")
# And the combination of both dataset are:
df = rbind(test, train[,-81])
# Import the necessary library
library(dplyr)
library(car)
library(missMDA)
library(FactoMineR)
source("LittleMCAR function.R")
# With the summary, we can see that there are 80 variables in total.
summary(test)
# And the name of each feature are below.
str(test)
# Analyzing all the feature will be an exhausting work. So there should be some way to reduce the dimensional. According to the statement of this project, we should retain all the numerical variable and 10 categorical variable.
# The categorical variable are below
Categorical_val = c('MSSubClass',"MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC","CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature","SaleType","SaleCondition", "LowQualFinSF", "PoolArea")
# The numerical variable are
Numerical_val = c("LotFrontage","LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal")
# And the date variable are
Date_val = c("YearBuilt","YearRemodAdd","GarageYrBlt","MoSold","YrSold")
# Find the numerical sets and categorical sets
test_num = select(test, Numerical_val); summary(test_num)
cat_num = select(test, Categorical_val); summary(cat_num)
# Some numerical variable just contain few unique values, which means can be converted into categorical. Here below we can see which of them.
sapply(select(df, Numerical_val), table)
sapply(select(df, Categorical_val), table)
# The LotFrontage has a percentage of missing quite high, 15,55% (227/1459). And it's the measure of distance from the property to the street. We'll need to check if it's by random or not, and decide to keep it or remove it.
# For this purpose, we'll use the Little test to validade if it's a MCAR, MAR or MNA.
# little.test <- LittleMCAR(test$LotFrontage)
# Assumptions 1. The PoolArea, although it's a Numerical variable, the percentage recorded is only 6 out of 1459 observations (0,4% of all data). So we thinks maybe can be reduced to a binary variable (Having or Not a Pool)
# Assumption 2. The LowQualFinSF is referring to Surface finished but with low quality. As same as PoolArea, there is only 14 unique observation different than 0. So we can reduce it into binary variable (Having or not a low quality surface.)
# Assumption 3. The LotFrontage has a percentage of missing quite high, 15,55% (227/1459). And it's the measure of distance from the property to the street. Using condes function, we can see that the relation between it and the target is 0.3518, with P-value 2,6*10^-36. We can consider to remove it.
# Assumption 4. The MSSubClass, OverallQual and OverallCond, although are categorical variables, they are presented as integer. So we need to transform it into factor.
#               For the OverallQual and OverallCond variable, their level are scaled from 1 to 10. Instead of that, we'll like to switch to categorical (Very pool to very Excelent)
# Assumption 5. Checking the categorical set, we found that "Exterior2nd" has a record of "Brk Cmn", which does not match with the data description "BrkComm". So we rename it.
# Assumption 6. For all those categorical variable that we find previously, we'll transform it into Factor.
# Assumption 1
test <- test %>%
mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
test$PoolArea = as.factor(test$PoolArea)
train <- train %>%
mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
train$PoolArea = as.factor(train$PoolArea)
# Assumption 2
test <- test %>%
mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
test$LowQualFinSF = as.factor(test$LowQualFinSF)
train <- train %>%
mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
train$LowQualFinSF = as.factor(train$LowQualFinSF)
# Assumption 3
test <- subset(test, select = -LotFrontage)
train <- subset(train, select = -LotFrontage)
# Assumption 4
breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
labels = c("Very Poor","Poor","Fair","Below Average","Average", "Above Averager", "Good", "Very Good", "Excellent", "Very Excellent")
test$OverallQual <- cut(test$OverallQual, breaks = breaks, labels = labels, include.lowest = TRUE)
test$OverallCond <- cut(test$OverallCond, breaks = breaks, labels = labels, include.lowest = TRUE)
train$OverallQual <- cut(train$OverallQual, breaks = breaks, labels = labels, include.lowest = TRUE)
train$OverallCond <- cut(train$OverallCond, breaks = breaks, labels = labels, include.lowest = TRUE)
test$MSSubClass = as.factor(test$MSSubClass)
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)
train$MSSubClass = as.factor(train$MSSubClass)
train$OverallQual = as.factor(train$OverallQual)
train$OverallCond = as.factor(train$OverallCond)
# Assumption 5.
names(test)[names(test) == "Brk Cmn"] <- "BrkComm"
# Assumption 6.
test <- test %>%
mutate_if(is.character, as.factor)
train <- train %>%
mutate_if(is.character, as.factor)
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(test_num)
severe_out
boxplt(test_num$LotFrontage)
boxplot(test_num$LotFrontage)
Boxplot(test_num$LotFrontage)
?Boxplot
res.PCA = imputePCA (select(test, Numerical_val))   # impute numeric variables
# Import the necessary library
library(dplyr)
library(car)
library(missMDA)
library(FactoMineR)
source("LittleMCAR function.R")
library(mice)
# With the summary, we can see that there are 80 variables in total.
summary(test)
# And the name of each feature are below.
str(test)
# Analyzing all the feature will be an exhausting work. So there should be some way to reduce the dimensional. According to the statement of this project, we should retain all the numerical variable and 10 categorical variable.
# The categorical variable are below
Categorical_val = c('MSSubClass',"MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC","CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature","SaleType","SaleCondition", "LowQualFinSF", "PoolArea")
# The numerical variable are
Numerical_val = c("LotFrontage","LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal")
# And the date variable are
Date_val = c("YearBuilt","YearRemodAdd","GarageYrBlt","MoSold","YrSold")
# Find the numerical sets and categorical sets
test_num = select(test, Numerical_val); summary(test_num)
# Assumption 1
test <- test %>%
mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
test$PoolArea = as.factor(test$PoolArea)
train <- train %>%
mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
train$PoolArea = as.factor(train$PoolArea)
# Assumption 2
test <- test %>%
mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
test$LowQualFinSF = as.factor(test$LowQualFinSF)
train <- train %>%
mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
train$LowQualFinSF = as.factor(train$LowQualFinSF)
# Assumption 3
test <- subset(test, select = -LotFrontage)
res.PCA = imputePCA (select(test, Numerical_val))   # impute numeric variables
Numerical_val_2 = c("LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal")
res.PCA = imputePCA (select(test, Numerical_val_2))   # impute numeric variables
select(test, Numerical_val_2)
str (res.PCA)
str(res.PCA$completeObs)
summary(res.PCA$completeObs)
summary(select(test, Numerical_val_2))
summary(res.PCA)
res.PCA$completeObs
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(res.PCA$completeObs)
test_pca = res.PCA$completeObs
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(test_pca)
library(chemometrics)
summary(test)
test$SaleType == NA's
summary(test)
test_impute = test_impute[-2489,]
test_impute = test[-2489,]
test_impute = test[-2489,]; summary(test_impute)
test_impute = test[-2489,]; summary(test_impute)
test_impute = test[-2489,]; summary(test_impute)
test_impute = test[-2485,]; summary(test_impute)
summary(test)
test_impute = test[-2485,]; summary(test_impute)
test_impute = test[-2485,]; summary(test_impute)
test_impute = test[-2485,]; summary(test_impute)
test_impute = test[-2485,]; summary(test_impute)
test_impute = test[-2485,]; summary(test_impute)
test_impute = test[-2485,]; summary(test_impute)
test_impute = test[-2485,]; summary(test_impute)
test_impute = test[-2485,]; summary(test_impute)
test_impute = test[-2485,]; summary(test_impute)
index = which(test$SaleType == NA)
index = which(test$SaleType == NA);index
# Load the data
if(!is.null(dev.list())) dev.off()
rm(list = ls())
test = read.csv("test.csv")
train = read.csv("train.csv")
# And the combination of both dataset are:
df = rbind(test, train[,-81])
# Chunk 1
# Load the data
if(!is.null(dev.list())) dev.off()
rm(list = ls())
test = read.csv("test.csv")
train = read.csv("train.csv")
# And the combination of both dataset are:
df = rbind(test, train[,-81])
# Chunk 2
# Import the necessary library
library(dplyr)
library(car)
library(missMDA)
library(FactoMineR)
source("LittleMCAR function.R")
library(mice)
library(chemometrics)
# Chunk 3
# With the summary, we can see that there are 80 variables in total.
summary(test)
# And the name of each feature are below.
str(test)
# Analyzing all the feature will be an exhausting work. So there should be some way to reduce the dimensional. According to the statement of this project, we should retain all the numerical variable and 10 categorical variable.
# The categorical variable are below
Categorical_val = c('MSSubClass',"MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC","CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature","SaleType","SaleCondition", "LowQualFinSF", "PoolArea")
# The numerical variable are
Numerical_val = c("LotFrontage","LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal")
Numerical_val_2 = c("LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal")
# And the date variable are
Date_val = c("YearBuilt","YearRemodAdd","GarageYrBlt","MoSold","YrSold")
# Chunk 4
# Find the numerical sets and categorical sets
test_num = select(test, Numerical_val); summary(test_num)
cat_num = select(test, Categorical_val); summary(cat_num)
# Some numerical variable just contain few unique values, which means can be converted into categorical. Here below we can see which of them.
sapply(select(df, Numerical_val), table)
sapply(select(df, Categorical_val), table)
# Chunk 5
# The LotFrontage has a percentage of missing quite high, 15,55% (227/1459). And it's the measure of distance from the property to the street. We'll need to check if it's by random or not, and decide to keep it or remove it.
# For this purpose, we'll use the Little test to validade if it's a MCAR, MAR or MNA.
# little.test <- LittleMCAR(test$LotFrontage)
# Chunk 6
# Assumptions 1. The PoolArea, although it's a Numerical variable, the percentage recorded is only 6 out of 1459 observations (0,4% of all data). So we thinks maybe can be reduced to a binary variable (Having or Not a Pool)
# Assumption 2. The LowQualFinSF is referring to Surface finished but with low quality. As same as PoolArea, there is only 14 unique observation different than 0. So we can reduce it into binary variable (Having or not a low quality surface.)
# Assumption 3. The LotFrontage has a percentage of missing quite high, 15,55% (227/1459). And it's the measure of distance from the property to the street. Using condes function, we can see that the relation between it and the target is 0.3518, with P-value 2,6*10^-36. We can consider to remove it.
# Assumption 4. The MSSubClass, OverallQual and OverallCond, although are categorical variables, they are presented as integer. So we need to transform it into factor.
#               For the OverallQual and OverallCond variable, their level are scaled from 1 to 10. Instead of that, we'll like to switch to categorical (Very pool to very Excelent)
# Assumption 5. Checking the categorical set, we found that "Exterior2nd" has a record of "Brk Cmn", which does not match with the data description "BrkComm". So we rename it.
# Assumption 6. For all those categorical variable that we find previously, we'll transform it into Factor.
# Chunk 7
# Assumption 1
test <- test %>%
mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
test$PoolArea = as.factor(test$PoolArea)
train <- train %>%
mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
train$PoolArea = as.factor(train$PoolArea)
# Assumption 2
test <- test %>%
mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
test$LowQualFinSF = as.factor(test$LowQualFinSF)
train <- train %>%
mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
train$LowQualFinSF = as.factor(train$LowQualFinSF)
# Assumption 3
test <- subset(test, select = -LotFrontage)
train <- subset(train, select = -LotFrontage)
# Assumption 4
breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
labels = c("Very Poor","Poor","Fair","Below Average","Average", "Above Averager", "Good", "Very Good", "Excellent", "Very Excellent")
test$OverallQual <- cut(test$OverallQual, breaks = breaks, labels = labels, include.lowest = TRUE)
test$OverallCond <- cut(test$OverallCond, breaks = breaks, labels = labels, include.lowest = TRUE)
train$OverallQual <- cut(train$OverallQual, breaks = breaks, labels = labels, include.lowest = TRUE)
train$OverallCond <- cut(train$OverallCond, breaks = breaks, labels = labels, include.lowest = TRUE)
test$MSSubClass = as.factor(test$MSSubClass)
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)
train$MSSubClass = as.factor(train$MSSubClass)
train$OverallQual = as.factor(train$OverallQual)
train$OverallCond = as.factor(train$OverallCond)
# Assumption 5.
names(test)[names(test) == "Brk Cmn"] <- "BrkComm"
# Assumption 6.
test <- test %>%
mutate_if(is.character, as.factor)
train <- train %>%
mutate_if(is.character, as.factor)
index = which(test$SaleType == NA);index
index = which(test$SaleType == 'NA');index
index = which(test$SaleType == 'NA's');index
index = which(test$SaleType == NA's);index
index = which(test$SaleType == NA);index
summary(test)
index = which(test$SaleType == Null);index
index = which(test$SaleType == NULL);index
index = which(test$SaleType == NA);index
index = which(test$SaleType == 'Con');index
index = which(test$SaleType == 'NA');index
# Load the data
if(!is.null(dev.list())) dev.off()
rm(list = ls())
test = read.csv("test.csv")
train = read.csv("train.csv")
# And the combination of both dataset are:
df = rbind(test, train[,-81])
index = which(test$SaleType == 'NA');index
test$SaleType
index = which(test$SaleType == "NA");index
index = which(test$GarageCars == "NA");index
index = which(test$GarageCars == "");index
index = which(test$GarageCars == "NA");index
test[1118,]
index = which(test$GarageCars == <NA>);index
index = which(test$GarageCars == "<NA>");index
index = which(test$GarageCars == '<NA>');index
test[2490,]
test[1031,]
test_impute = test[-c(1118,1031),]; summary(test_impute)
summary(test)
# Chunk 1
# Load the data
if(!is.null(dev.list())) dev.off()
rm(list = ls())
test = read.csv("test.csv")
train = read.csv("train.csv")
# And the combination of both dataset are:
df = rbind(test, train[,-81])
# Chunk 2
# Import the necessary library
library(dplyr)
library(car)
library(missMDA)
library(FactoMineR)
source("LittleMCAR function.R")
library(mice)
library(chemometrics)
# Chunk 3
# With the summary, we can see that there are 80 variables in total.
summary(test)
# And the name of each feature are below.
str(test)
# Analyzing all the feature will be an exhausting work. So there should be some way to reduce the dimensional. According to the statement of this project, we should retain all the numerical variable and 10 categorical variable.
# The categorical variable are below
Categorical_val = c('MSSubClass',"MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC","CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature","SaleType","SaleCondition", "LowQualFinSF", "PoolArea")
# The numerical variable are
Numerical_val = c("LotFrontage","LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal")
Numerical_val_2 = c("LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal")
# And the date variable are
Date_val = c("YearBuilt","YearRemodAdd","GarageYrBlt","MoSold","YrSold")
# Chunk 4
# Find the numerical sets and categorical sets
test_num = select(test, Numerical_val); summary(test_num)
cat_num = select(test, Categorical_val); summary(cat_num)
# Some numerical variable just contain few unique values, which means can be converted into categorical. Here below we can see which of them.
sapply(select(df, Numerical_val), table)
sapply(select(df, Categorical_val), table)
# Chunk 5
# The LotFrontage has a percentage of missing quite high, 15,55% (227/1459). And it's the measure of distance from the property to the street. We'll need to check if it's by random or not, and decide to keep it or remove it.
# For this purpose, we'll use the Little test to validade if it's a MCAR, MAR or MNA.
# little.test <- LittleMCAR(test$LotFrontage)
# Chunk 6
# Assumptions 1. The PoolArea, although it's a Numerical variable, the percentage recorded is only 6 out of 1459 observations (0,4% of all data). So we thinks maybe can be reduced to a binary variable (Having or Not a Pool)
# Assumption 2. The LowQualFinSF is referring to Surface finished but with low quality. As same as PoolArea, there is only 14 unique observation different than 0. So we can reduce it into binary variable (Having or not a low quality surface.)
# Assumption 3. The LotFrontage has a percentage of missing quite high, 15,55% (227/1459). And it's the measure of distance from the property to the street. Using condes function, we can see that the relation between it and the target is 0.3518, with P-value 2,6*10^-36. We can consider to remove it.
# Assumption 4. The MSSubClass, OverallQual and OverallCond, although are categorical variables, they are presented as integer. So we need to transform it into factor.
#               For the OverallQual and OverallCond variable, their level are scaled from 1 to 10. Instead of that, we'll like to switch to categorical (Very pool to very Excelent)
# Assumption 5. Checking the categorical set, we found that "Exterior2nd" has a record of "Brk Cmn", which does not match with the data description "BrkComm". So we rename it.
# Assumption 6. For all those categorical variable that we find previously, we'll transform it into Factor.
# Chunk 7
# Assumption 1
test <- test %>%
mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
test$PoolArea = as.factor(test$PoolArea)
train <- train %>%
mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
train$PoolArea = as.factor(train$PoolArea)
# Assumption 2
test <- test %>%
mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
test$LowQualFinSF = as.factor(test$LowQualFinSF)
train <- train %>%
mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
train$LowQualFinSF = as.factor(train$LowQualFinSF)
# Assumption 3
test <- subset(test, select = -LotFrontage)
train <- subset(train, select = -LotFrontage)
# Assumption 4
breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
labels = c("Very Poor","Poor","Fair","Below Average","Average", "Above Averager", "Good", "Very Good", "Excellent", "Very Excellent")
test$OverallQual <- cut(test$OverallQual, breaks = breaks, labels = labels, include.lowest = TRUE)
test$OverallCond <- cut(test$OverallCond, breaks = breaks, labels = labels, include.lowest = TRUE)
train$OverallQual <- cut(train$OverallQual, breaks = breaks, labels = labels, include.lowest = TRUE)
train$OverallCond <- cut(train$OverallCond, breaks = breaks, labels = labels, include.lowest = TRUE)
test$MSSubClass = as.factor(test$MSSubClass)
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)
train$MSSubClass = as.factor(train$MSSubClass)
train$OverallQual = as.factor(train$OverallQual)
train$OverallCond = as.factor(train$OverallCond)
# Assumption 5.
names(test)[names(test) == "Brk Cmn"] <- "BrkComm"
# Assumption 6.
test <- test %>%
mutate_if(is.character, as.factor)
train <- train %>%
mutate_if(is.character, as.factor)
res.PCA = imputePCA (select(test, Numerical_val_2))   # impute numeric variables
str (res.PCA)
str(res.PCA$completeObs)
summary(res.PCA$completeObs)
test_impute = res.PCA$completeObs; summary(test_impute)
test_impute = res.PCA$completeObs; summary(test_impute)
summary(test)
summary(test_num)
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(test_pca)
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. It the record appear in both Uni&Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(test_impute)
severe_out
Boxplot(test_num$LotFrontage)
res.mout <- Moutlier(test_impute, quantile = 0.95)
test_impute
summary(test_impute)
res.mout <- Moutlier(test_impute[,-MasVnrArea], quantile = 0.95)
res.mout <- Moutlier(test_impute[,-"MasVnrArea"], quantile = 0.95)
res.mout <- Moutlier(test_impute, quantile = 0.95)
res.mout <- Moutlier(test_impute, quantile = 0.995)
# Univariate Outlier
# Here we'll check all the Univariate outlier, and highlight them. In the next section, we'll do it but for multiple outlier. If the record appear in both Uni&Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(test_impute)
severe_out
Boxplot(test_num$LotFrontage)
res.mout <- Moutlier(test_impute[,-3], quantile = 0.995)
summary(test_impute)
res.mout <- Moutlier(test_impute[,c(-2,-3)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(-2,-3,-4)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,1], quantile = 0.995)
res.mout <- Moutlier(test_impute[,1:2], quantile = 0.995)
res.mout <- Moutlier(test_impute[,2], quantile = 0.995)
res.mout <- Moutlier(test_impute[,3], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,4)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,6)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,8)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,8)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,9)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,9)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,10)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,11)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,12)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,13)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,15], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,15)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,18)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,20)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21,22)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21,23)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21,24)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21,25], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21,25)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21,26)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21,27)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21,28)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21)], quantile = 0.995)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21)], quantile = 0.95)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21)], quantile = 0.95)
par(mfrow = c(1,1))
plot(res.mout$md, res.mout$rd, col="cyan", pch = 19)
res.mout <- Moutlier(test_impute[,c(1,3,5,7,16,17,19,21)], quantile = 0.95)
plot(res.mout$md, res.mout$rd, col="cyan", pch = 19)
res.mout$cutoff
abline(h=res.mout$cutoff, col="red", lwd = 2)
abline(v=res.mout$cutoff, col="red", lwd = 2)
text(res.mout$md, res.mout$rd, label = row.names(df), cex = 0.5)
ll <- which ((res.mout$md>res.mout$cutoff) &
res.mout$rd>res.mout$cutoff); ll
