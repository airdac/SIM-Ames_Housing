---
title: "SIM Project 1"
author: "Adrià Casanova", "Víctor Garcia", "Zhengyong Ji"
date: "November, 19th 2023"
output: 
  pdf_document: 
    toc: true
    toc_depth: 3
    number_sections: true
editor_options: 
  chunk_output_type: console
---

# The file contains some numeric variables (retain all of them) and many factors (restrict to 10 to reduce the effort).

**Data preparation**

```{r,echo=FALSE}
# Load the data
if(!is.null(dev.list())) dev.off()
rm(list = ls())

train = read.csv("train.csv")
test = read.csv("test.csv")

# And the combination of both datasets is:
df = rbind(test, train[,-81])

```

Done - Removing duplicate or irrelevant observations
Done - Fix structural errors (usually coding errors, trailing blanks in labels, lower/upper case consistency, etc.).
Done - Check data types. Dates should be coded as such and factors should have level names (if possible, levels have to be set and clarify the variable they belong to). This point is sometimes included under data transformation process. New derived variables are to be produced sometimes scaling and/or normalization (range/shape changes to numeric variables) or category regrouping for factors (nominal/ordinal).
Done - Filter unwanted outliers. Univariate and multivariate outliers have to be highlighted. Remove register/erase values and set NA for univariate outiers.
In process - Handle missing data: figure out why the data is missing. Data imputation is to be considered when the aim is modelling (imputation has to be validated).


- Data validation is mixed of ‘common sense and sector knowledge’: Does the data make sense? Does the data follow the appropriate rules for its field? Does it prove or disprove the working theory, or bring any insight to light? Can you find trends in the data to help you form a new theory? If not, is that because of a data quality issue?

```{r}
# Import the necessary libraries and do a first EDA

library(car)
library(mice)
library(dplyr) 
library(missMDA)
library(FactoMineR)
library(chemometrics)
library(DataExplorer)
library(corrplot)
library(DataExplorer)

#create_report(train, output_format = "pdf_document", output_file = "train.pdf")
#create_report(test, output_format = "pdf_document", output_file = "test.pdf")
```

**0. Pre-processing and data preparation**
Any data set for modelling purposes should include a first methodological step on data preparation about

```{r}
# With the summary, we can see that there are 80 variables in total.
summary(train)
# And the name of each feature are below.
str(train)
# Analyzing all features will be an exhausting work. So there should be some way to reduce the dimensions. According to the statement of the project, we should retain all numerical variables and 10 categorical variables.

# The categorical variable are below

Categorical_val = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC","CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature","SaleType","SaleCondition", "MoSold")

# The numerical variables except the target are

Numerical_val = c("LotFrontage","LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal","YearBuilt","YearRemodAdd","GarageYrBlt","YrSold")

# And the date variables are

Date_val = c("YearBuilt","YearRemodAdd","GarageYrBlt","MoSold","YrSold")

```


```{r}
# Some numerical variables just contain a few unique values, which means they can be converted to categorical. Below we can see which of them.
sapply(select(train, Numerical_val), table)
sapply(select(train, Categorical_val), table)
sapply(select(train, Date_val), table)

```


# General Assumptions

```{r}
# Assumptions 1. PoolArea, although it's a numerical variable, the percentage recorded is less than 0.5% in train and test. So we thinks maybe can be reduced to a binary variable (Having or Not a Pool)
length(which(train$PoolArea > 0))/dim(train)[1]*100
length(which(test$PoolArea > 0))/dim(test)[1]*100

# Assumption 2. LowQualFinSF is referring to Surface finished but with low quality. As same as PoolArea, only 2% of the values in train and 1% in test are positive. So we can reduce it into a binary variable (having or not a low quality surface.)
length(which(train$LowQualFinSF > 0))/dim(train)[1]*100
length(which(test$LowQualFinSF > 0))/dim(test)[1]*100

#Assumtption 3. The same happens with BsmtFinSF2 with only 12% of positive values.
length(which(train$BsmtFinSF2 > 0))/dim(train)[1]*100
length(which(test$BsmtFinSF2 > 0))/dim(test)[1]*100

# Assumption 4. LotFrontage, which represents the distance from the property to the street, has a high percentage of missing values, 18% in "train" and 16% in "test". Now we should check if data is missing by random or not using the Little test. However, this test is implemented in the LittleMCAR function, which accepts data frames with at most 50 variables. Both train and test datasets are too large, so we will have to make a decision with other tools.

# A quick look at the summary of LotFrontage in both datasets shows there isn't any house with a value of 0 for this variable. However, in the real world there exist houses whose entrance is right next to the street, with no separation from it. Hence, we deduce that missing values correspond to a distance of 0 and we impute LotFrontage like so.

# Assumption 5. BsmtHalfBath is numerical but it can only be 0, 1 or 2. Moreover, only 6% of values are positive, so we'll transform it to a categorical.
length(which(train$BsmtHalfBath > 0))/dim(train)[1]*100
length(which(test$BsmtHalfBath > 0))/dim(test)[1]*100

# Assumption 6. Similarly, KitchenAbvGr can only be 0, 1, 2 or 3 and only 5% is different than 1.
length(which(train$KitchenAbvGr != 1))/dim(train)[1]*100
length(which(test$KitchenAbvGr != 1))/dim(test)[1]*100

# Assumption 7. Most values of EnclosedPorch, X3SsnPorch, ScreenPorch are 0. Below we can see the percentage of each variable in train and test. Hence, we will transform them to a binary variable that tells whether the dwelling has a porch of the corresponding kind.
length(which(train$EnclosedPorch > 0))/dim(train)[1]*100
length(which(test$EnclosedPorch > 0))/dim(test)[1]*100
length(which(train$X3SsnPorch > 0))/dim(train)[1]*100
length(which(test$X3SsnPorch > 0))/dim(test)[1]*100
length(which(train$ScreenPorch > 0))/dim(train)[1]*100
length(which(test$ScreenPorch > 0))/dim(test)[1]*100

# Assumption 8. MiscVal has only a 4% of values different to 0. However, converting it to binary would be redundant, because wether a dwelling has a miscellaneous feature or not can already be studied with the MiscFeature categorical variable. Hence, we have decided to remove this variable from both train and test, storing its values in a new R variable in case we need it for further study.
length(which(train$MiscVal > 0))/dim(train)[1]*100
length(which(test$MiscVal > 0))/dim(test)[1]*100

# Assumption 9. We'll transform all the categorical variables we found previously into Factor.

# Assumption 10. Missings in categorical variables Alley, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, FireplaceQu, GarageType, GarageFinish, GarageQual, GarageCond, PoolQC, Fence, MiscFeature correspond to a new level, so they cannot be imputed. Instead, we create this new level and declare it as all missings for each variable. Some of these missing values could be really missing and hence should me imputed with other methods. However, the rest of variables have at most 1% of missings, so we can assume that just a few records will be imputed wrongly. We have found this information by doing an automatic profile generated using the SmartEDA library, which can be found in the EDA section.

# Assumption 11. The MSSubClass, OverallQual and OverallCond, although are categorical variables, they are presented as integer. So we need to transform it into factor.

# Assumption 12. Checking the set of categories, we found that "Exterior2nd" has a record of "Brk Cmn", which does not match with the data description "BrkComm". So we rename it (in order to match with "Exterior1st")

# Assumption 13. Month will be transformed into factor and renamed to abbreviated names, while other dates as year will remain numerical.

# Note that the numerical variables we have converted to categorical were exactly those whose IQR was 0, since finding their univariate outliers would have been very complicated.
```

# Data transformation

```{r}
# Assumption 1

test <- test %>%
  mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
test$PoolArea = as.factor(test$PoolArea)
train <- train %>%
  mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
train$PoolArea = as.factor(train$PoolArea)

# Assumption 2
test <- test %>%
  mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
test$LowQualFinSF = as.factor(test$LowQualFinSF)
train <- train %>%
  mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
train$LowQualFinSF = as.factor(train$LowQualFinSF)

# Assumption 3
test <- test %>%
  mutate(BsmtFinSF2 = ifelse(BsmtFinSF2 > 0, "Yes", "No"))
test$BsmtFinSF2 = as.factor(test$BsmtFinSF2)
train <- train %>%
  mutate(BsmtFinSF2 = ifelse(BsmtFinSF2 > 0, "Yes", "No"))
train$BsmtFinSF2 = as.factor(train$BsmtFinSF2)

# Assumption 4

percent_miss <- function(data) {
  return (length(which(is.na(data)))/length(data)*100)
}
percent_miss(train$LotFrontage)
percent_miss(test$LotFrontage)

summary(train$LotFrontage)
summary(test$LotFrontage)

lltrain <- which(is.na(train$LotFrontage))
lltest <- which(is.na(test$LotFrontage))
train$LotFrontage[lltrain] <- 0
test$LotFrontage[lltest] <- 0

# Assumption 5
train$BsmtHalfBath <- as.factor(train$BsmtHalfBath)
test$BsmtHalfBath <- as.factor(test$BsmtHalfBath)

# Assumption 6
train$KitchenAbvGr <- as.factor(train$KitchenAbvGr)
test$KitchenAbvGr <- as.factor(test$KitchenAbvGr)
levels(test$KitchenAbvGr) = c(levels(test$KitchenAbvGr),"3")

# Assumption 7
test <- test %>%
  mutate(EnclosedPorch = ifelse(EnclosedPorch > 0, "Yes", "No"))
test$EnclosedPorch = as.factor(test$EnclosedPorch)
train <- train %>%
  mutate(EnclosedPorch = ifelse(EnclosedPorch > 0, "Yes", "No"))
train$EnclosedPorch = as.factor(train$EnclosedPorch)
test <- test %>%
  mutate(X3SsnPorch = ifelse(X3SsnPorch > 0, "Yes", "No"))
test$X3SsnPorch = as.factor(test$X3SsnPorch)
train <- train %>%
  mutate(X3SsnPorch = ifelse(X3SsnPorch > 0, "Yes", "No"))
train$X3SsnPorch = as.factor(train$X3SsnPorch)
test <- test %>%
  mutate(ScreenPorch = ifelse(ScreenPorch > 0, "Yes", "No"))
test$ScreenPorch = as.factor(test$ScreenPorch)
train <- train %>%
  mutate(ScreenPorch = ifelse(ScreenPorch > 0, "Yes", "No"))
train$ScreenPorch = as.factor(train$ScreenPorch)

# Assumption 8
miscVal_train <- train$MiscVal
miscVal_test <- test$MiscVal
train$MiscVal <- NULL
test$MiscVal <- NULL

# Assumption 9
test <- test %>%
  mutate_if(is.character, as.factor)
train <- train %>%
  mutate_if(is.character, as.factor)

# Assumption 10
# Alley, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, FireplaceQu, GarageType, GarageFinish, GarageQual, GarageCond, PoolQC, Fence, MiscFeature

levels(train$Alley) <- c(levels(train$Alley), "NAlley")
train$Alley[which(is.na(train$Alley))] <- "NAlley"
levels(test$Alley) <- c(levels(test$Alley), "NAlley")
test$Alley[which(is.na(test$Alley))] <- "NAlley"

levels(train$BsmtQual) <- c(levels(train$BsmtQual), "NBsmt")
train$BsmtQual[which(is.na(train$BsmtQual))] <- "NBsmt"
levels(test$BsmtQual) <- c(levels(test$BsmtQual), "NBsmt")
test$BsmtQual[which(is.na(test$BsmtQual))] <- "NBsmt"

levels(train$BsmtCond) <- c(levels(train$BsmtCond), "NBsmt")
train$BsmtCond[which(is.na(train$BsmtCond))] <- "NBsmt"
levels(test$BsmtCond) <- c(levels(test$BsmtCond), "NBsmt")
test$BsmtCond[which(is.na(test$BsmtCond))] <- "NBsmt"

levels(train$BsmtExposure) <- c(levels(train$BsmtExposure), "NBsmt")
train$BsmtExposure[which(is.na(train$BsmtExposure))] <- "NBsmt"
levels(test$BsmtExposure) <- c(levels(test$BsmtExposure), "NBsmt")
test$BsmtExposure[which(is.na(test$BsmtExposure))] <- "NBsmt"

levels(train$BsmtFinType1) <- c(levels(train$BsmtFinType1), "NBsmt")
train$BsmtFinType1[which(is.na(train$BsmtFinType1))] <- "NBsmt"
levels(test$BsmtFinType1) <- c(levels(test$BsmtFinType1), "NBsmt")
test$BsmtFinType1[which(is.na(test$BsmtFinType1))] <- "NBsmt"

levels(train$BsmtFinType2) <- c(levels(train$BsmtFinType2), "NBsmt")
train$BsmtFinType2[which(is.na(train$BsmtFinType2))] <- "NBsmt"
levels(test$BsmtFinType2) <- c(levels(test$BsmtFinType2), "NBsmt")
test$BsmtFinType2[which(is.na(test$BsmtFinType2))] <- "NBsmt"

levels(train$FireplaceQu) <- c(levels(train$FireplaceQu), "NFp")
train$FireplaceQu[which(is.na(train$FireplaceQu))] <- "NFp"
levels(test$FireplaceQu) <- c(levels(test$FireplaceQu), "NFp")
test$FireplaceQu[which(is.na(test$FireplaceQu))] <- "NFp"

levels(train$GarageType) <- c(levels(train$GarageType), "NGar")
train$GarageType[which(is.na(train$GarageType))] <- "NGar"
levels(test$GarageType) <- c(levels(test$GarageType), "NGar")
test$GarageType[which(is.na(test$GarageType))] <- "NGar"

levels(train$GarageFinish) <- c(levels(train$GarageFinish), "NGar")
train$GarageFinish[which(is.na(train$GarageFinish))] <- "NGar"
levels(test$GarageFinish) <- c(levels(test$GarageFinish), "NGar")
test$GarageFinish[which(is.na(test$GarageFinish))] <- "NGar"

levels(train$GarageQual) <- c(levels(train$GarageQual), "NGar")
train$GarageQual[which(is.na(train$GarageQual))] <- "NGar"
levels(test$GarageQual) <- c(levels(test$GarageQual), "NGar")
test$GarageQual[which(is.na(test$GarageQual))] <- "NGar"

levels(train$GarageCond) <- c(levels(train$GarageCond), "NGar")
train$GarageCond[which(is.na(train$GarageCond))] <- "NGar"
levels(test$GarageCond) <- c(levels(test$GarageCond), "NGar")
test$GarageCond[which(is.na(test$GarageCond))] <- "NGar"

levels(train$PoolQC) <- c(levels(train$PoolQC), "NPool")
train$PoolQC[which(is.na(train$PoolQC))] <- "NPool"
levels(test) <- c(levels(test$PoolQC), "NPool")
test$PoolQC[which(is.na(test$PoolQC))] <- "NPool"

levels(train$Fence) <- c(levels(train$Fence), "NFen")
train$Fence[which(is.na(train$Fence))] <- "NFen"
levels(test$Fence) <- c(levels(test$Fence), "NFen")
test$Fence[which(is.na(test$Fence))] <- "NFen"

levels(train$MiscFeature) <- c(levels(train$MiscFeature), "N")
train$MiscFeature[which(is.na(train$MiscFeature))] <- "N"
levels(test$MiscFeature) <- c(levels(test$MiscFeature), "N")
test$MiscFeature[which(is.na(test$MiscFeature))] <- "N"

# Assumption 11

test$MSSubClass = as.factor(test$MSSubClass)
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)

train$MSSubClass = as.factor(train$MSSubClass)
train$OverallQual = as.factor(train$OverallQual)
train$OverallCond = as.factor(train$OverallCond)

# Assumption 12
names(test)[names(test) == "Brk Cmn"] <- "BrkComm"

# Assumption 13.
test$MoSold = month.name[test$MoSold]
test$MoSold = as.factor(test$MoSold)
train$MoSold = month.name[train$MoSold]
train$MoSold = as.factor(train$MoSold)

summary(test)

```

```{r}
# Find numerical, categorical and date variables
id_num_val = which(sapply(test, is.numeric)==TRUE)
# We won't analyze the id variable
id_num_val = as.numeric(id_num_val)[-1]; id_num_val
id_cat_val = which(sapply(test, is.factor)==TRUE)
id_cat_val = as.numeric(id_cat_val); id_cat_val
id_date_val = c(20,21,60,77,78)
# Now, the categorical variable are below

Categorical_val = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","BsmtFinSF2","Heating","HeatingQC","CentralAir","Electrical","LowQualFinSF","BsmtHalfBath","KitchenAbvGr","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","EnclosedPorch","X3SsnPorch","ScreenPorch","PoolArea","PoolQC","Fence","MiscFeature","SaleType","SaleCondition","MoSold")

# The numerical variables except the target are

Numerical_val = c("LotFrontage","LotArea","YearBuilt","YearRemodAdd","MasVnrArea","BsmtFinSF1","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","FullBath","HalfBath","BedroomAbvGr","TotRmsAbvGrd","Fireplaces","GarageYrBlt","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","YrSold")
train_num = select(train, Numerical_val); summary(train_num)
train_cat = select(train, Categorical_val); summary(train_cat)
```


# Univariate Outliers

```{r}
# Here we'll check all the Univariate outliers, and highlight them. In the next section, we'll do it but for multiple outliers. If a record appears in Uni or Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(train_num); severe_out
# There are 26 numerical variables, so we will automatize this step by erasing all severe univariate outliers and setting them to NA. After validating the results, we will imputate them with the rest of missing values. There will be one exception, SalePrice. Since it is the target, we can't impute it, so we will remove the whole records with severe outliers instead.

severe_outliers <- function(data) {
  ss <- summary(data)
  # Upper/lower severe thresholds
  utso <- as.numeric(ss[5]+3*(ss[5]-ss[2]))
  ltso <- as.numeric(ss[2]-3*(ss[5]-ss[2]))
  
  return (which((data>utso)|(data<ltso)))
}

par(mfrow=c(1,2))
for (var in id_num_val) {
  train[severe_outliers(train[,var]),var] <- NA
  Boxplot(train[,var], ylab = var, main = "Train")
  test[severe_outliers(test[,var]),var] <- NA
  Boxplot(test[,var], ylab = var, main = "Test")
}
par(mfrow=c(1,1))
train = train[-severe_outliers(train$SalePrice),]
Boxplot(train$SalePrice)
```

# PCA imputation

After the detection of univariate outliers, that were declared as NA's, we decided to impute all those missings for numerical variables. The variables that contained most missings were "GarageYrBlt" (6% in train and 5% in test), "MasVnrArea" (2% in train and 3% in test),  and "OpenPorchSF"(1% in both). As the quartile distribution for all imputed variables are similar we conclude that the imputation was successful for all variables. A box plot is also provided to check the distributions visually

```{r}
percent_miss(train$GarageYrBlt)
percent_miss(test$GarageYrBlt)
percent_miss(train$MasVnrArea)
percent_miss(test$MasVnrArea)
percent_miss(train$OpenPorchSF)
percent_miss(test$OpenPorchSF)
```


```{r}
# In this section we'll Performance PCA to impute the missing data for numerical variables

res.PCA = imputePCA (train[,id_num_val])   # impute numeric variables
str (res.PCA)
str(res.PCA$completeObs)

# We can observe that the missing values are imputed.
train_impute = data.frame(res.PCA$completeObs)
train_impute$SalePrice <- train$SaleP

```

```{r}
# Check if the imputation was successful or not
before_imputation = summary(train[,id_num_val])
after_imputation = summary(train_impute)


label = c('Before imputation', 'After imputation')

for (x in c(1,2,5,6,8,9,11,15,16,18,20,21,22)) {
d = data.frame(A = train[,id_num_val][x], B = train_impute[,x])
b = boxplot(d, names=label, main = names(train[,id_num_val][x]));
b
}
```

Now we do the same for the test dataset

```{r}
# In this section we'll Performance PCA to impute the missing data for numerical variables

res.PCA.test = imputePCA (test[,id_num_val])   # impute numeric variables
str (res.PCA.test)
str(res.PCA.test$completeObs)

# We can observe that the missing values are imputed.
test_impute = data.frame(res.PCA.test$completeObs)
```

```{r}
# Check if the imputation was successful or not
before_imputation_test = summary(test[,id_num_val])
after_imputation_test = summary(test_impute)


label = c('Before imputation', 'After imputation')

for (x in c(1,2,5,6,8,9,11,15,16,18,20,21,22)) {
d = data.frame(A = test[,id_num_val][x], B = test_impute[,x])
b = boxplot(d, names=label, main = names(test[,id_num_val][x]));
b
}
```

# Multivariate Outliers Analysis

After the imputation, we decided to perform a Moutlier analysis to detect multivariate outliers. As using all numerical variables returns a singular matrix we decided to make the analysis with only the following variables: "LotFrontage", "LotArea", "YearRemodAdd", "BsmtFinSF1", "BsmtUnfSF", "GrLivArea", "Fireplaces", "GarageYrBlt", "GarageArea".

The analysis showed that there are 112 multivariate outliers in the train dataset and 115 in the test datset.

```{r}
# In the multivariate outlier, as this is stochastic, we cannot plot all the features. After several attempts, the best combination is below
id_num_val
id_num_val_not_corr = c(1, 2, 4, 6, 7, 11, 17,
                        18, 20)

# The analysis gives that all values from classical Mahalanobis distance
# are NA, as a consequence it is only possible to plot robust Mahalanobis distance.
# According to this distance there are 436 outliers (30 % of all data), however,
# none of them is considered an outlier by the classical Mahalanobis distance.
res.mout <- Moutlier(train_impute[,id_num_val_not_corr], quantile = 0.95, plot= FALSE)

par(mfrow=c(1,2))
plot(res.mout$md, col="lightblue", pch = 19, main = 'Detection of multivariable 
outliers', xlab= 'Observation', 
     ylab ='Traditional Mahalanobis distance ')
abline(h = res.mout$cutoff, col = "red", lwd = 5, lty = 2)

plot(res.mout$rd, col="lightblue", pch = 19, xlab= 'Observation', 
     ylab ='Robust Mahalanobis distance ')
abline(h = res.mout$cutoff, col = "red", lwd = 5, lty = 2)
par(mfrow=c(1,1))

outliers = which(res.mout$md>res.mout$cutoff & res.mout$rd > res.mout$cutoff) 
length(outliers)
```

Now we do the same for the test dataset

```{r}
res.mout.test <- Moutlier(test_impute[,id_num_val_not_corr], quantile = 0.95, plot= FALSE)
par(mfrow=c(1,2))
plot(res.mout.test$md, col="lightblue", pch = 19, main = 'Detection of multivariable 
outliers', xlab= 'Observation', 
     ylab ='Traditional Mahalanobis distance ')
abline(h = res.mout.test$cutoff, col = "red", lwd = 5, lty = 2)

plot(res.mout.test$rd, col="lightblue", pch = 19, xlab= 'Observation', 
     ylab ='Robust Mahalanobis distance ')
abline(h = res.mout.test$cutoff, col = "red", lwd = 5, lty = 2)
par(mfrow=c(1,1))

outliers.test = which(res.mout.test$md>res.mout.test$cutoff & res.mout.test$rd > res.mout.test$cutoff) 
length(outliers.test)
```


# Select 10 Categorical features

Once we have the data clean and preprocesed, we have selected the 10 most relevant
categories. To do that we analysed which categorical variables are most relevant 
according to the profile of FactoMiner. 

```{r}
# Use condes() method to determine the correlation between categorical feature and the target SalePrice.
res.con = condes(train, 80)         
res.con$quanti
res.con$quali
res.con$category
```

We analysed only the "train" database and using "SalePrice" and selected the
categorical variables with an smaller p-value. We also selected all numerical variables except for "YrSold", which had a large p-value. Furthermore, we have used cor.test() to test against H0="correlation between "YrSold" and "SalePrice" is 0" and we have failted to reject H0. Therefore, "YrSold" cannot be used to model "SalePrice".

The variables that we selected, sorted starting with the smallest p-value, are:
OverallQual, Neighborhood, ExterQual, BsmtQual, KitchenQual, GarageFinish  
FireplaceQu, Foundation, GarageType and MSSubClass.

```{r}
cor.test(train$YrSold, train$SalePrice)
res.con$quali[1:10,]
```


# EDA
An extensive EDA was done for the imputed values of "train" database, before and
after the imputation, as well as to "test" database. Note that "train" contains 1460 observations of houses that were sold, and "test" contains 1459 different observations of houses without a sell price. 

In this context the most relevant conclusions of EDA, considering all numerical values and
the selected categorical variables, are: 

1 - "Train" and "test" databases contains observations that follows a
similar distribution for all variables, numerical and categorical. 

2 - There are no missing values for numerical variables, as we decided to impute them. For the categorical, we created a new level that contains the missings for each variable. 

3 - Both databases are highly unbalanced in almost all categories. 
This is specially relevant in variables like "ExterQual" or "Foundation", where only 2 out of 6 categories retains 86% of the accumulative probability.

4 - 'Neighborhood' has 25 levels, all of them contains similar number of observations 
(from 0.13 to 5%).

5 - Numerical variables have a non normal distribution according to Shapiro–Wilk 
and Kolmogorov-Smirnov tests. This is specially relevant for the target variable.

```{r, echo=FALSE}

#create_report(train_impute, output_format = "pdf_document", output_file = "train_imputed.pdf")
#create_report(test_impute, output_format = "pdf_document", output_file = "test_imputed.pdf")

#library(SmartEDA)

#ExpReport(train, op_file = 'train_before_imputation_SMARTEDA.html')
#ExpReport(test, op_file = 'test_before_imputation_SMARTEDA.html')
#ExpReport(train_impute, op_file = 'train_before_imputation_SMARTEDA.html')
```


```{r}
# Analysis of Neighborhood
summary(train$Neighborhood)

# % of all levels
a = 100* table(train$Neighborhood) / length(train$Neighborhood)

plot(train$Neighborhood)
count = c(17, 2, 16, 58, 28, 150, 51, 100, 79, 37, 17, 49, 225,
                37, 9, 73, 73, 112, 74, 59, 86, 22, 25, 38, 11)
lbls = levels(train$Neighborhood)

pie(count,labels = lbls, col=rainbow(length(lbls)),
   main="Summary of Neighborhood")
```

```{r}
# Tests for normality (done in all numerical variables)
ks.test(train$LotArea, y = 'pnorm')
shapiro.test(train$LotArea)
```

# Analysis of correlation
Using the basic profiling of Factominer we discover that the most correlated numerical variables with the target, with more than 50 % of R^2 are: GrLivArea, GarageCars, GarageArea, TotalBsmtSF, X1stFlrSF, YearBuilt, FullBath, YearRemodAdd, GarageYrBlt and TotRmsAbvGrd.

```{r}
res.con = condes(train, 80)         
res.con$quanti
```

As variables are not normally distributed, created the correlation matrix of all numerical variables using spearman. The result is ploted in a correlation plot,
where we performed a cluster analysis to sort the variables, so that variables that are more correlated are placed closer to each other. Additionally, we decided to create 5 clusters, as we do not expect to work with a model with more than 5 numerical variables. Also, note that in this plot the target variable is not included as this analysis was already done.

The interpretation of this plot suggest that positive correlations are more common than negative, where the most important is between BsmtFullBath and BsmtFin with BsmtUnfSF. Also, there are some important positve correlarions that must be considered when making the model, for example, GarageArea is hightly correlated with GarageCars, so both variables should not be included in the same model.


```{r}
# Analysis of correlations. We use spearman because there is not normality
library(corrplot)
library(magrittr)

corr_mat = cor(train_num, method = 'spearman', use = "complete.obs")

#corrplot(corr_mat, method = 'color', order = 'alphabet')

corrplot(corr_mat, order = 'hclust', addrect = 5)

# Code to make clusters using the name of variables
#corrplot(corr_mat, order = 'AOE') %>%
#  corrRect(name = c(
#    'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', 'X1stFlrSF', #'YearBuilt', 'FullBath', 'YearRemodAdd', 'GarageYrBlt', 'TotRmsAbvGrd'))
```

Here we select the variables we will use to discover the model
```{r}
#Cat_var <- c("OverallQual", "Neighborhood", "ExterQual", "BsmtQual", "KitchenQual", "GarageFinish", "FireplaceQu", "Foundation", "GarageType", "MSSubClass")

train_impute$OverallQual <- train$OverallQual
train_impute$Neighborhood <- train$Neighborhood
train_impute$ExterQual <- train$ExterQual
train_impute$BsmtQual <- train$BsmtQual
train_impute$KitchenQual <- train$KitchenQual
train_impute$GarageFinish <- train$GarageFinish
train_impute$FireplaceQu <- train$FireplaceQu
train_impute$Foundation <- train$Foundation
train_impute$GarageType <- train$GarageType
train_impute$MSSubClass <- train$MSSubClass
train_impute$YrSold <- NULL

write.csv(train_impute, file='train_impute.csv', row.names = FALSE)
```


**DONE 3. Determine if the response variable (charges) has an acceptably normal distribution.**

**DONE 4. Address tests to discard serial correlation.**

**DONE 5. Detect univariant and multivariant outliers, errors and missing values (if any) and apply an imputation technique if needed.**


**6. Preliminary exploratory analysis to describe observed relations has to be undertaken.**


**7. If you can improve linear relations or limit the effect of influential data, you must consider suitable transformations for variables.**

```{r}


```


**8. Apart from the retained factor variables, you can consider other categorical variables that can be defined from categorized numeric variables. Do not forget to implement new variable definitions in the test sample.**

```{r}

```


**9. You must take into account possible interactions between categorical and numerical variables.**

```{r}

```


**10. When building the model, you should study the presence of multi-collinearity and try to reduce their impact on the model for easier interpretation. **

```{r}

```


**11. You should build the model using a technique for selecting variables (removing no significant predictors and/or stepwise selection of the best models).**

```{r}

```


**12.The validation of the model has to be done with graphs and / or suitable tests to verify model assumptions.**

```{r}

```


**13. You must include the study of unusual and / or influential data. **

```{r}

```


**14. The resulting model should be interpreted in terms of the relationships of selected predictors and its effect on the response variable. **

```{r}

```


**15. You have to apply your final model to the test sample and roughly assess forecasting capability.**

```{r}

```

