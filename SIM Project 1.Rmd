---
title: "SIM Project 1"
author: "Adrià Casanova", "Víctor Garcia", "Zhengyong Ji"
date: "November, 19th 2023"
output: 
  pdf_document: 
    toc: true
    toc_depth: 3
    number_sections: true
editor_options: 
  chunk_output_type: console
---

# The file contains some numeric variables (retain all of them) and many factors (restrict to 10 to reduce the effort).

**Data preparation**

```{r,echo=FALSE}
# Load the data
if(!is.null(dev.list())) dev.off()
rm(list = ls())

train = read.csv("train.csv")
test = read.csv("test.csv")

# And the combination of both dataset are:
df = rbind(test, train[,-81])

```

Done - Removing duplicate or irrelevant observations
Done - Fix structural errors (usually coding errors, trailing blanks in labels, lower/upper case consistency, etc.).
Done - Check data types. Dates should be coded as such and factors should have level names (if possible, levels have to be set and clarify the variable they belong to). This point is sometimes included under data transformation process. New derived variables are to be produced sometimes scaling and/or normalization (range/shape changes to numeric variables) or category regrouping for factors (nominal/ordinal).
Done - Filter unwanted outliers. Univariate and multivariate outliers have to be highlighted. Remove register/erase values and set NA for univariate outiers.
In process - Handle missing data: figure out why the data is missing. Data imputation is to be considered when the aim is modelling (imputation has to be validated).


- Data validation is mixed of ‘common sense and sector knowledge’: Does the data make sense? Does the data follow the appropriate rules for its field? Does it prove or disprove the working theory, or bring any insight to light? Can you find trends in the data to help you form a new theory? If not, is that because of a data quality issue?

```{r}
# Import the necessary library

library(car)
library(mice)
library(dplyr) 
library(missMDA)
library(FactoMineR)
library(chemometrics)
library(DataExplorer)
source("LittleMCAR function.R")

```

**0. Pre-processing and data preparation**
Any data set for modelling purposes should include a first methodological step on data preparation about

```{r}
# With the summary, we can see that there are 80 variables in total.
summary(train)
# And the name of each feature are below.
str(train)
# Analyzing all the feature will be an exhausting work. So there should be some way to reduce the dimensional. According to the statement of this project, we should retain all the numerical variable and 10 categorical variable.

# The categorical variable are below

Categorical_val = c('MSSubClass',"MSZoning","Street","Alley","LotShape","LandContour","Utilities","LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType","HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC","CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature","SaleType","SaleCondition", "LowQualFinSF", "PoolArea")

# The numerical variable are

Numerical_val = c("LotFrontage","LotArea","MasVnrArea","BsmtFinSF1","BsmtFinSF2","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","X2ndFlrSF","GrLivArea","BsmtFullBath","BsmtHalfBath","FullBath","HalfBath","BedroomAbvGr","KitchenAbvGr","TotRmsAbvGrd","Fireplaces","GarageCars","GarageArea","WoodDeckSF","OpenPorchSF","EnclosedPorch","X3SsnPorch","ScreenPorch","MiscVal")

# And the date variables are

Date_val = c("YearBuilt","YearRemodAdd","GarageYrBlt","MoSold","YrSold")

```


```{r}
# Some numerical variable just contain few unique values, which means can be converted into categorical. Here below we can see which of them.
sapply(select(train, Numerical_val), table)
sapply(select(train, Categorical_val), table)
sapply(select(train, Date_val), table)

```


```{r}


```


# General Assumptions

```{r}
# Assumptions 1. The PoolArea, although it's a Numerical variable, the percentage recorded is only 7 out of 1459 observations (0,48% of all data). So we thinks maybe can be reduced to a binary variable (Having or Not a Pool)

# Assumption 2. The LowQualFinSF is referring to Surface finished but with low quality. As same as PoolArea, there is only 23 unique observation different than 0. So we can reduce it into binary variable (Having or not a low quality surface.)

# Assumption 3. LotFrontage, which represents the distance from the property to the street, has a high percentage of missing values, 18% in "train" and 16% in "test". Now we should check if data is missing by random or not using the Little test. However, this test is implemented in the LittleMCAR function, which accepts data frames with at most 50 variables. Both train and test datasets are too large, so we will have to make a decision with other tools.

# A quick look at the summary of LotFrontage in both datasets shows there isn't any house with a value of 0 for this variable. However, in the real world there exist houses whose entrance is right next to the street, with no separation from it. Hence, we deduce that missing values correspond to a distance of 0 and we impute LotFrontage like so.

# Assumption 4. The MSSubClass, OverallQual and OverallCond, although are categorical variables, they are presented as integer. So we need to transform it into factor.

# Assumption 5. Checking the set of categories, we found that "Exterior2nd" has a record of "Brk Cmn", which does not match with the data description "BrkComm". So we rename it (in order to match with "Exterior1st")

# Assumption 6. We'll transform all the categorical variables we found previously into Factor.

# Assumption 7. Month will be transformed into factor and renamed to abbreviated names, while other dates as year will remain numerical.

```

# Data transformation

```{r}
# Assumption 1

test <- test %>%
  mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
test$PoolArea = as.factor(test$PoolArea)
train <- train %>%
  mutate(PoolArea = ifelse(PoolArea > 0, "Yes", "No"))
train$PoolArea = as.factor(train$PoolArea)

# Assumption 2
test <- test %>%
  mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
test$LowQualFinSF = as.factor(test$LowQualFinSF)
train <- train %>%
  mutate(LowQualFinSF = ifelse(LowQualFinSF > 0, "Yes", "No"))
train$LowQualFinSF = as.factor(train$LowQualFinSF)

# Assumption 3

percent_miss <- function(data) {
  return (length(which(is.na(data)))/length(data)*100)
}
percent_miss(train$LotFrontage)
percent_miss(test$LotFrontage)

summary(train$LotFrontage)
summary(test$LotFrontage)

lltrain <- which(is.na(train$LotFrontage))
lltest <- which(is.na(test$LotFrontage))
train$LotFrontage[lltrain] <- 0
test$LotFrontage[lltest] <- 0

# Assumption 4
#breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
#labels = c("Very Poor","Poor","Fair","Below Average","Average", "Above Average", "Good", "Very Good", "Excellent", "Very Excellent")


#test$OverallQual <- cut(test$OverallQual, breaks = breaks, labels = labels, include.lowest = TRUE)
#test$OverallCond <- cut(test$OverallCond, breaks = breaks, labels = labels, include.lowest = TRUE)

#train$OverallQual <- cut(train$OverallQual, breaks = breaks, labels = labels, include.lowest = TRUE)
#train$OverallCond <- cut(train$OverallCond, breaks = breaks, labels = labels, include.lowest = TRUE)

test$MSSubClass = as.factor(test$MSSubClass)
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)

train$MSSubClass = as.factor(train$MSSubClass)
train$OverallQual = as.factor(train$OverallQual)
train$OverallCond = as.factor(train$OverallCond)

# Assumption 5.
names(test)[names(test) == "Brk Cmn"] <- "BrkComm"

# Assumption 6.
test <- test %>%
  mutate_if(is.character, as.factor)
train <- train %>%
  mutate_if(is.character, as.factor)

# Assumption 7.
test$MoSold = month.name[test$MoSold]
test$MoSold = as.factor(test$MoSold)
train$MoSold = month.name[train$MoSold]
train$MoSold = as.factor(train$MoSold)

summary(test)

```

```{r}
# Find numerical variables
train_num = select(train, Numerical_val_2); summary(train_num)
train_cat = select(train, Categorical_val); summary(train_cat)
```


# Univariate Outliers

```{r}
# Here we'll check all the Univariate outliers, and highlight them. In the next section, we'll do it but for multiple outliers. If a record appears in Uni or Mult outlier analysis, then we'll remove it.
severe_out = Boxplot(train_num)
# We have to check better these outliers
severe_out

```

# Multivariate Outliers Analysis

```{r}
# In the multivariate outlier, as this is stochastic, we cannot plot all the features. After several attempts, the best combination is below

res.mout <- Moutlier(train_num[,c(1,3,5,7,16,17,19,21)], quantile = 0.95)
#par(mfrow = c(1,1))
plot(res.mout$md, res.mout$rd, col="cyan", pch = 19)
res.mout$cutoff
abline(h=res.mout$cutoff, col="red", lwd = 2)
abline(v=res.mout$cutoff, col="red", lwd = 2)

text(res.mout$md, res.mout$rd, label = row.names(train_num), cex = 1)

ll <- which ((res.mout$md>res.mout$cutoff) & (res.mout$rd>res.mout$cutoff)); ll

# So we'll remove them from the test data set.
train_clean = train_num[-ll,]

```


# PCA imputation

```{r}
# In this section we'll Performance PCA to impute the missing data for numerical variables

res.PCA = imputePCA (train_clean)   # impute numeric variables
str (res.PCA)
str(res.PCA$completeObs)

# We can observe that the missing values are imputed.
train_impute = res.PCA$completeObs; summary(train_impute)
```

# Select 10 Categorical feature

```{r}
# Once we have the data clean and preprocesed, we'll get into the selection of the categorical feature, leaving only with 10 of then.

# Because there are too many qualitative variables we need to select 10 of them. Note that qualitative variables in both datasets are the same but, according to the EDA, distributions are different. As a consequence, we expect correlations to be different as well.

# To analyse which categorical variables are most relevant we performed profiling using FactoMiner. Analysing only the "train" database and using "SalePrice" as our target variable have analysed the 10 most important categorical variables to predict the price. Those are:

"
Variable      R^2         p value
OverallQual   0.684181287 0.000000e+00
Neighborhood  0.545574991 1.558600e-225
ExterQual     0.477387778 1.439551e-204
BsmtQual      0.464993778 8.158548e-196
KitchenQual   0.456598624 3.032213e-192
GarageFinish  0.305873737 6.228747e-115
FireplaceQu   0.293960754 2.971217e-107
Foundation    0.256368402  5.791895e-91
GarageType    0.249204231  6.117026e-87
MSSubClass    0.246315973  8.662166e-79
"
```


```{r}
# Use condes method to determinate the correlation between categorical feature and the target SalePrice.
res.con = condes(train, 80)         
res.con$quanti
res.con$quali
res.con$category
```

From those 10 variables, we can perform the same analysis but using each categorical variable

```{r}
#res.cat=catdes(train, 17) # df = columns without missings
#res.cat$test.chi2
#res.cat$category
#res.cat$quanti.var; res.cat$quanti
```


```{r}
# Once we have set the correct type of each variable we can start analyzing the database. We can do a quick EDA on both databases using automatic tools like "DataExplorer".

# Using those reports we see that databases "test" and "train" have the same variables except for "SalePrice", that can only be found in "train". In more detail, we can see that the "train" db contains 1460 observations of houses that were sold, and "test" contains 1459 different observations of houses we don't know the price of. We will work to predict the price of the latter.

```


```{r, echo=FALSE}
# load DataExplorer library
# use create_report 
# create_report(train)
# create_report(test)

```


**3. Determine if the response variable (charges) has an acceptably normal distribution.**

```{r}

```


**4. Address tests to discard serial correlation.**

```{r}

```


**5. Detect univariant and multivariant outliers, errors and missing values (if any) and apply an imputation technique if needed.**

```{r}

```


**6. Preliminary exploratory analysis to describe observed relations has to be undertaken.**

```{r}

```


**7. If you can improve linear relations or limit the effect of influential data, you must consider suitable transformations for variables.**

```{r}

```


**8. Apart from the retained factor variables, you can consider other categorical variables that can be defined from categorized numeric variables. Do not forget to implement new variable definitions in the test sample.**

```{r}

```


**9. You must take into account possible interactions between categorical and numerical variables.**

```{r}

```


**10. When building the model, you should study the presence of multi-collinearity and try to reduce their impact on the model for easier interpretation. **

```{r}

```


**11. You should build the model using a technique for selecting variables (removing no significant predictors and/or stepwise selection of the best models).**

```{r}

```


**12.The validation of the model has to be done with graphs and / or suitable tests to verify model assumptions.**

```{r}

```


**13. You must include the study of unusual and / or influential data. **

```{r}

```


**14. The resulting model should be interpreted in terms of the relationships of selected predictors and its effect on the response variable. **

```{r}

```


**15. You have to apply your final model to the test sample and roughly assess forecasting capability.**

```{r}

```

